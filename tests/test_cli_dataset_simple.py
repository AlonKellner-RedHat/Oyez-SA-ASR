# Generated by Claude
"""Tests for dataset simple CLI command - basic tests."""

import json
import tempfile
from pathlib import Path

import numpy as np
import pyarrow as pa
import pyarrow.parquet as pq
from typer.testing import CliRunner

from oyez_sa_asr.audio_utils import save_audio
from oyez_sa_asr.cli import app
from oyez_sa_asr.cli_dataset_simple import _group_utterances_by_recording

runner = CliRunner()


def _create_test_flac(path: Path, duration_sec: float = 10.0) -> None:
    """Create a test FLAC audio file."""
    sample_rate = 16000
    t = np.linspace(0, duration_sec, int(duration_sec * sample_rate), dtype=np.float32)
    samples = np.sin(2 * np.pi * 440 * t) * 0.5
    samples = samples[np.newaxis, :]
    path.parent.mkdir(parents=True, exist_ok=True)
    save_audio(samples, sample_rate, path, format="flac", bits_per_sample=16)


class TestDatasetSimple:
    """Tests for dataset simple command."""

    def test_help(self) -> None:
        """Shows help."""
        result = runner.invoke(app, ["dataset", "simple", "--help"])
        assert result.exit_code == 0
        assert "simple dataset" in result.output.lower()

    def test_requires_flex_dataset(self) -> None:
        """Fails if flex dataset doesn't exist."""
        with tempfile.TemporaryDirectory() as tmpdir:
            flex_dir = Path(tmpdir) / "flex"
            output_dir = Path(tmpdir) / "simple"

            result = runner.invoke(
                app,
                [
                    "dataset",
                    "simple",
                    "--flex-dir",
                    str(flex_dir),
                    "--output-dir",
                    str(output_dir),
                ],
            )

            assert result.exit_code == 1
            assert "not found" in result.output

    def test_embeds_audio(self) -> None:
        """Embeds audio bytes into parquet files."""
        with tempfile.TemporaryDirectory() as tmpdir:
            flex_dir = Path(tmpdir) / "flex"
            output_dir = Path(tmpdir) / "simple"

            (flex_dir / "data").mkdir(parents=True)
            (flex_dir / "audio" / "2024" / "22-123").mkdir(parents=True)

            # Edited by Claude: Added transcript_type field
            recordings = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "recording_id": "20240101a",
                    "transcript_type": "oral_argument",
                    "audio_path": "2024/22-123/20240101a.flac",
                }
            ]

            pq.write_table(
                pa.Table.from_pylist(recordings),
                flex_dir / "data" / "recordings.parquet",
            )

            utterances = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "transcript_type": "oral_argument",
                    "text": "Test utterance one",
                    "word_count": 3,
                    "speaker_name": "Roberts",
                    "start_sec": 0.0,
                    "end_sec": 3.0,
                    "duration_sec": 3.0,
                },
                {
                    "term": "2024",
                    "docket": "22-123",
                    "transcript_type": "oral_argument",
                    "text": "Test utterance two",
                    "word_count": 3,
                    "speaker_name": "Sotomayor",
                    "start_sec": 5.0,
                    "end_sec": 8.0,
                    "duration_sec": 3.0,
                },
            ]
            pq.write_table(
                pa.Table.from_pylist(utterances),
                flex_dir / "data" / "utterances.parquet",
            )

            flac_path = flex_dir / "audio" / "2024" / "22-123" / "20240101a.flac"
            _create_test_flac(flac_path, duration_sec=10.0)

            (flex_dir / "index.json").write_text(json.dumps({"terms": ["2024"]}))

            result = runner.invoke(
                app,
                [
                    "dataset",
                    "simple-lt1m",  # Use single flavor for testing
                    "--flex-dir",
                    str(flex_dir),
                    "--output-dir",
                    str(output_dir),
                ],
            )

            assert result.exit_code == 0
            assert (output_dir / "data" / "utterances").exists()
            assert (output_dir / "index.json").exists()


class TestGroupUtterancesByRecording:
    """Tests for utterance grouping logic.

    Edited by Claude: Updated tests to use 3-tuple key (term, docket, transcript_type).
    """

    def test_groups_by_term_docket_type(self) -> None:
        """Groups utterances by (term, docket, transcript_type) key."""
        utterances = [
            {
                "term": "2024",
                "docket": "22-123",
                "transcript_type": "oral_argument",
                "text": "a",
                "start_sec": 0.0,
            },
            {
                "term": "2024",
                "docket": "22-123",
                "transcript_type": "oral_argument",
                "text": "b",
                "start_sec": 5.0,
            },
            {
                "term": "2024",
                "docket": "22-456",
                "transcript_type": "opinion",
                "text": "c",
                "start_sec": 0.0,
            },
            {
                "term": "2023",
                "docket": "21-789",
                "transcript_type": "oral_argument",
                "text": "d",
                "start_sec": 0.0,
            },
        ]

        grouped = _group_utterances_by_recording(utterances)

        assert len(grouped) == 3
        assert len(grouped[("2024", "22-123", "oral_argument")]) == 2
        assert len(grouped[("2024", "22-456", "opinion")]) == 1
        assert len(grouped[("2023", "21-789", "oral_argument")]) == 1

    def test_separates_oral_argument_and_opinion(self) -> None:
        """Separates oral_argument and opinion for same case."""
        utterances = [
            {
                "term": "2022",
                "docket": "21-86",
                "transcript_type": "oral_argument",
                "text": "We will hear argument",
                "start_sec": 0.0,
            },
            {
                "term": "2022",
                "docket": "21-86",
                "transcript_type": "opinion",
                "text": "Justice Kagan has the opinion",
                "start_sec": 0.0,
            },
        ]

        grouped = _group_utterances_by_recording(utterances)

        # Should be separate groups, not combined
        assert len(grouped) == 2
        assert len(grouped[("2022", "21-86", "oral_argument")]) == 1
        assert len(grouped[("2022", "21-86", "opinion")]) == 1
        assert (
            grouped[("2022", "21-86", "oral_argument")][0]["text"]
            == "We will hear argument"
        )
        assert (
            grouped[("2022", "21-86", "opinion")][0]["text"]
            == "Justice Kagan has the opinion"
        )

    def test_preserves_utterance_data(self) -> None:
        """Preserves all utterance fields when grouping."""
        utterances = [
            {
                "term": "2024",
                "docket": "22-123",
                "transcript_type": "oral_argument",
                "text": "hello",
                "speaker_name": "Roberts",
                "start_sec": 1.0,
                "end_sec": 3.5,
            }
        ]

        grouped = _group_utterances_by_recording(utterances)

        utt = grouped[("2024", "22-123", "oral_argument")][0]
        assert utt["text"] == "hello"
        assert utt["speaker_name"] == "Roberts"
        assert utt["start_sec"] == 1.0
        assert utt["end_sec"] == 3.5

    def test_empty_list(self) -> None:
        """Handles empty utterances list."""
        grouped = _group_utterances_by_recording([])
        assert grouped == {}

    def test_missing_transcript_type_defaults_to_unknown(self) -> None:
        """Uses 'unknown' for missing transcript_type."""
        utterances = [
            {"term": "2024", "docket": "22-123", "text": "no type", "start_sec": 0.0},
        ]

        grouped = _group_utterances_by_recording(utterances)

        assert len(grouped) == 1
        assert ("2024", "22-123", "unknown") in grouped


class TestDurationFlavors:
    """Tests for duration-based simple dataset commands."""

    def test_lt1m_help(self) -> None:
        """simple-lt1m shows help."""
        result = runner.invoke(app, ["dataset", "simple-lt1m", "--help"])
        assert result.exit_code == 0
        assert "< 1 minute" in result.output

    def test_lt5m_help(self) -> None:
        """simple-lt5m shows help."""
        result = runner.invoke(app, ["dataset", "simple-lt5m", "--help"])
        assert result.exit_code == 0
        assert "1-5 minutes" in result.output

    def test_lt30m_help(self) -> None:
        """simple-lt30m shows help."""
        result = runner.invoke(app, ["dataset", "simple-lt30m", "--help"])
        assert result.exit_code == 0
        assert "5-30 minutes" in result.output

    def test_lt1m_default_workers(self) -> None:
        """simple-lt1m defaults to 8 workers."""
        result = runner.invoke(app, ["dataset", "simple-lt1m", "--help"])
        assert "default: 8" in result.output.lower()

    def test_lt30m_default_workers(self) -> None:
        """simple-lt30m defaults to 1 worker."""
        result = runner.invoke(app, ["dataset", "simple-lt30m", "--help"])
        assert "default: 1" in result.output.lower()
