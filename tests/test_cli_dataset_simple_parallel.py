# Generated by Claude
"""Tests for parallel processing in dataset simple."""

import json
import tempfile
from pathlib import Path

import numpy as np
import pyarrow as pa
import pyarrow.parquet as pq
from typer.testing import CliRunner

from oyez_sa_asr.audio_utils import save_audio
from oyez_sa_asr.cli import app

runner = CliRunner()


def _create_test_flac(path: Path, duration_sec: float = 10.0) -> None:
    """Create a test FLAC audio file."""
    sample_rate = 16000
    t = np.linspace(0, duration_sec, int(duration_sec * sample_rate), dtype=np.float32)
    samples = np.sin(2 * np.pi * 440 * t) * 0.5
    samples = samples[np.newaxis, :]
    path.parent.mkdir(parents=True, exist_ok=True)
    save_audio(samples, sample_rate, path, format="flac", bits_per_sample=16)


class TestParallelProcessing:
    """Tests for parallel recording processing."""

    def test_workers_option_in_help(self) -> None:
        """Workers option appears in help."""
        result = runner.invoke(app, ["dataset", "simple-lt1m", "--help"])
        assert result.exit_code == 0
        assert "--workers" in result.output or "-w" in result.output

    def test_processes_with_single_worker(self) -> None:
        """Processes correctly with single worker."""
        with tempfile.TemporaryDirectory() as tmpdir:
            flex_dir = Path(tmpdir) / "flex"
            output_dir = Path(tmpdir) / "simple"

            (flex_dir / "data").mkdir(parents=True)
            audio_subdir = flex_dir / "audio" / "2024" / "22-123"
            audio_subdir.mkdir(parents=True)

            _create_test_flac(audio_subdir / "20240101a.flac", duration_sec=5.0)

            recordings = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "recording_id": "20240101a",
                    "audio_path": "2024/22-123/20240101a.flac",
                }
            ]
            pq.write_table(
                pa.Table.from_pylist(recordings),
                flex_dir / "data" / "recordings.parquet",
            )

            utterances = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "transcript_type": "oral_argument",
                    "text": "Test utterance one",
                    "word_count": 3,
                    "speaker_name": "Roberts",
                    "start_sec": 0.0,
                    "end_sec": 2.0,
                    "duration_sec": 2.0,
                },
                {
                    "term": "2024",
                    "docket": "22-123",
                    "transcript_type": "oral_argument",
                    "text": "Test utterance two",
                    "word_count": 3,
                    "speaker_name": "Sotomayor",
                    "start_sec": 5.0,
                    "end_sec": 8.0,
                    "duration_sec": 3.0,
                },
            ]
            pq.write_table(
                pa.Table.from_pylist(utterances),
                flex_dir / "data" / "utterances.parquet",
            )
            (flex_dir / "index.json").write_text(json.dumps({"terms": ["2024"]}))

            result = runner.invoke(
                app,
                [
                    "dataset",
                    "simple-lt1m",
                    "--flex-dir",
                    str(flex_dir),
                    "--output-dir",
                    str(output_dir),
                    "--workers",
                    "1",
                ],
            )

            assert result.exit_code == 0
            assert (output_dir / "data" / "utterances").exists()

    def test_processes_with_multiple_workers(self) -> None:
        """Processes correctly with multiple workers."""
        with tempfile.TemporaryDirectory() as tmpdir:
            flex_dir = Path(tmpdir) / "flex"
            output_dir = Path(tmpdir) / "simple"

            (flex_dir / "data").mkdir(parents=True)
            recordings = []
            utterances = []

            for i in range(3):
                docket = f"22-{i:03d}"
                audio_subdir = flex_dir / "audio" / "2024" / docket
                audio_subdir.mkdir(parents=True)
                _create_test_flac(
                    audio_subdir / f"recording_{i}.flac", duration_sec=5.0
                )

                recordings.append(
                    {
                        "term": "2024",
                        "docket": docket,
                        "recording_id": f"recording_{i}",
                        "audio_path": f"2024/{docket}/recording_{i}.flac",
                    }
                )
                utterances.append(
                    {
                        "term": "2024",
                        "docket": docket,
                        "transcript_type": "oral_argument",
                        "text": f"Test utterance number {i}",
                        "word_count": 4,
                        "speaker_name": "Speaker",
                        "start_sec": 0.0,
                        "end_sec": 2.0,
                        "duration_sec": 2.0,
                    }
                )
                # Add second utterance to avoid too_long_ratio filter
                utterances.append(
                    {
                        "term": "2024",
                        "docket": docket,
                        "transcript_type": "oral_argument",
                        "text": f"Second test {i}",
                        "word_count": 3,
                        "speaker_name": "Speaker2",
                        "start_sec": 3.0,
                        "end_sec": 5.0,
                        "duration_sec": 2.0,
                    }
                )

            pq.write_table(
                pa.Table.from_pylist(recordings),
                flex_dir / "data" / "recordings.parquet",
            )
            pq.write_table(
                pa.Table.from_pylist(utterances),
                flex_dir / "data" / "utterances.parquet",
            )
            (flex_dir / "index.json").write_text(json.dumps({"terms": ["2024"]}))

            result = runner.invoke(
                app,
                [
                    "dataset",
                    "simple-lt1m",
                    "--flex-dir",
                    str(flex_dir),
                    "--output-dir",
                    str(output_dir),
                    "--workers",
                    "2",
                ],
            )

            assert result.exit_code == 0

            output_parquet = list(
                (output_dir / "data" / "utterances").glob("*.parquet")
            )
            assert len(output_parquet) >= 1

            table = pq.read_table(output_parquet[0])
            rows = table.to_pylist()
            # 3 recordings x 2 utterances each = 6 total
            assert len(rows) == 6
