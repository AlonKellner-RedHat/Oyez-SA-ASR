# Generated by Claude
"""Tests for skip-if-exists caching in dataset simple."""

import json
import tempfile
from pathlib import Path

import numpy as np
import pyarrow as pa
import pyarrow.parquet as pq
from typer.testing import CliRunner

from oyez_sa_asr.audio_utils import save_audio
from oyez_sa_asr.cli import app

runner = CliRunner()


def _create_test_flac(path: Path, duration_sec: float = 10.0) -> None:
    """Create a test FLAC audio file."""
    sample_rate = 16000
    t = np.linspace(0, duration_sec, int(duration_sec * sample_rate), dtype=np.float32)
    samples = np.sin(2 * np.pi * 440 * t) * 0.5
    samples = samples[np.newaxis, :]
    path.parent.mkdir(parents=True, exist_ok=True)
    save_audio(samples, sample_rate, path, format="flac", bits_per_sample=16)


class TestSkipExisting:
    """Tests for skip-if-exists caching."""

    def test_skips_if_index_exists(self) -> None:
        """Skips processing if output index.json already exists."""
        with tempfile.TemporaryDirectory() as tmpdir:
            flex_dir = Path(tmpdir) / "flex"
            output_dir = Path(tmpdir) / "simple"

            (flex_dir / "data").mkdir(parents=True)
            audio_subdir = flex_dir / "audio" / "2024" / "22-123"
            audio_subdir.mkdir(parents=True)

            _create_test_flac(audio_subdir / "20240101a.flac", duration_sec=5.0)

            recordings = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "recording_id": "20240101a",
                    "audio_path": "2024/22-123/20240101a.flac",
                }
            ]
            pq.write_table(
                pa.Table.from_pylist(recordings),
                flex_dir / "data" / "recordings.parquet",
            )

            utterances = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "text": "Test",
                    "speaker_name": "Roberts",
                    "start_sec": 0.0,
                    "end_sec": 2.0,
                }
            ]
            pq.write_table(
                pa.Table.from_pylist(utterances),
                flex_dir / "data" / "utterances.parquet",
            )
            (flex_dir / "index.json").write_text(json.dumps({"terms": ["2024"]}))

            # Pre-create the output index
            output_dir.mkdir(parents=True)
            (output_dir / "index.json").write_text(
                json.dumps({"utterances_embedded": 999})
            )

            result = runner.invoke(
                app,
                [
                    "dataset",
                    "simple",
                    "--flex-dir",
                    str(flex_dir),
                    "--output-dir",
                    str(output_dir),
                ],
            )

            assert result.exit_code == 0
            assert "Skipping" in result.output or "already exists" in result.output

            with (output_dir / "index.json").open() as f:
                index = json.load(f)
            assert index["utterances_embedded"] == 999

    def test_force_regeneration_option(self) -> None:
        """--force flag forces regeneration even if output exists."""
        with tempfile.TemporaryDirectory() as tmpdir:
            flex_dir = Path(tmpdir) / "flex"
            output_dir = Path(tmpdir) / "simple"

            (flex_dir / "data").mkdir(parents=True)
            audio_subdir = flex_dir / "audio" / "2024" / "22-123"
            audio_subdir.mkdir(parents=True)

            _create_test_flac(audio_subdir / "20240101a.flac", duration_sec=5.0)

            recordings = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "recording_id": "20240101a",
                    "audio_path": "2024/22-123/20240101a.flac",
                }
            ]
            pq.write_table(
                pa.Table.from_pylist(recordings),
                flex_dir / "data" / "recordings.parquet",
            )

            utterances = [
                {
                    "term": "2024",
                    "docket": "22-123",
                    "text": "Test",
                    "speaker_name": "Roberts",
                    "start_sec": 0.0,
                    "end_sec": 2.0,
                }
            ]
            pq.write_table(
                pa.Table.from_pylist(utterances),
                flex_dir / "data" / "utterances.parquet",
            )
            (flex_dir / "index.json").write_text(json.dumps({"terms": ["2024"]}))

            output_dir.mkdir(parents=True)
            (output_dir / "index.json").write_text(
                json.dumps({"utterances_embedded": 999})
            )

            result = runner.invoke(
                app,
                [
                    "dataset",
                    "simple",
                    "--flex-dir",
                    str(flex_dir),
                    "--output-dir",
                    str(output_dir),
                    "--force",
                ],
            )

            assert result.exit_code == 0

            with (output_dir / "index.json").open() as f:
                index = json.load(f)
            assert index["utterances_embedded"] == 1
