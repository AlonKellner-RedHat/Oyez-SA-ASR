# Generated by Claude
"""Tests for scrape transcripts functionality."""

import json
import re
import tempfile
from pathlib import Path
from unittest.mock import AsyncMock, patch

from typer.testing import CliRunner

from oyez_sa_asr.cli import app
from oyez_sa_asr.scraper.parser_cases import extract_media_urls
from oyez_sa_asr.scraper.parser_transcripts import build_transcript_to_case_map

runner = CliRunner()


def strip_ansi(text: str) -> str:
    """Remove ANSI escape codes from text."""
    return re.sub(r"\x1b\[[0-9;]*m", "", text)


class TestExtractMediaUrls:
    """Tests for extract_media_urls function."""

    def test_extracts_oral_arguments(self) -> None:
        """Should extract oral argument hrefs."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            case_data = {
                "oral_arguments": [
                    {"href": "https://example.com/oral/1", "unavailable": False},
                    {"href": "https://example.com/oral/2", "unavailable": False},
                ],
                "opinion_announcements": [],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert "https://example.com/oral/1" in urls
            assert "https://example.com/oral/2" in urls

    def test_extracts_opinion_announcements(self) -> None:
        """Should extract opinion announcement hrefs."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            case_data = {
                "oral_arguments": [],
                "opinion_announcements": [
                    {"href": "https://example.com/opinion/1", "unavailable": False},
                ],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert "https://example.com/opinion/1" in urls

    def test_skips_unavailable(self) -> None:
        """Should skip entries marked as unavailable."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            case_data = {
                "oral_arguments": [
                    {"href": "https://example.com/available", "unavailable": False},
                    {"href": "https://example.com/unavailable", "unavailable": True},
                ],
                "opinion_announcements": [],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert "https://example.com/available" in urls
            assert "https://example.com/unavailable" not in urls

    def test_handles_empty_cases_dir(self) -> None:
        """Should return empty list for empty directory."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            urls = extract_media_urls(cases_dir)
            assert urls == []

    def test_handles_multiple_terms(self) -> None:
        """Should collect URLs from multiple term directories."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)

            for term in ["2021", "2022"]:
                term_dir = cases_dir / term
                term_dir.mkdir()
                case_data = {
                    "oral_arguments": [
                        {
                            "href": f"https://example.com/{term}/oral",
                            "unavailable": False,
                        }
                    ],
                    "opinion_announcements": [],
                }
                (term_dir / "test.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert len(urls) == 2
            assert "https://example.com/2021/oral" in urls
            assert "https://example.com/2022/oral" in urls

    def test_deduplicates_urls(self) -> None:
        """Should not return duplicate URLs."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            # Two cases with same oral argument
            for name in ["case1.json", "case2.json"]:
                case_data = {
                    "oral_arguments": [
                        {"href": "https://example.com/same", "unavailable": False}
                    ],
                    "opinion_announcements": [],
                }
                (term_dir / name).write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert urls.count("https://example.com/same") == 1


class TestScrapeTranscriptsCommand:
    """Tests for scrape transcripts CLI command."""

    def test_scrape_transcripts_help(self) -> None:
        """Should show help for scrape transcripts."""
        result = runner.invoke(app, ["scrape", "transcripts", "--help"])
        assert result.exit_code == 0
        output = strip_ansi(result.output)
        assert "--cases-dir" in output
        assert "--cache-dir" in output

    def test_scrape_transcripts_empty_cases(self) -> None:
        """Should handle empty cases directory gracefully."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir) / "cases"
            cases_dir.mkdir()
            cache_dir = Path(tmpdir) / "cache"

            result = runner.invoke(
                app,
                [
                    "scrape",
                    "transcripts",
                    "--cases-dir",
                    str(cases_dir),
                    "--cache-dir",
                    str(cache_dir),
                ],
            )

            assert result.exit_code == 0
            assert "No media URLs" in result.output or "0" in result.output

    def test_scrape_transcripts_fetches_urls(self) -> None:
        """Should fetch media URLs from processed cases."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir) / "cases"
            term_dir = cases_dir / "2022"
            term_dir.mkdir(parents=True)
            cache_dir = Path(tmpdir) / "cache"

            # Create a case file with media URLs
            case_data = {
                "oral_arguments": [
                    {"href": "https://example.com/oral/1", "unavailable": False}
                ],
                "opinion_announcements": [
                    {"href": "https://example.com/opinion/1", "unavailable": False}
                ],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            with patch(
                "oyez_sa_asr.cli_scrape_transcripts.AdaptiveFetcher"
            ) as mock_fetcher_cls:
                mock_fetcher = mock_fetcher_cls.create.return_value
                mock_fetcher.fetch_batch_adaptive = AsyncMock(return_value=[])

                result = runner.invoke(
                    app,
                    [
                        "scrape",
                        "transcripts",
                        "--cases-dir",
                        str(cases_dir),
                        "--cache-dir",
                        str(cache_dir),
                    ],
                )

                assert result.exit_code == 0
                # Should have called fetch_batch_adaptive with 2 URLs
                mock_fetcher.fetch_batch_adaptive.assert_called_once()
                call_args = mock_fetcher.fetch_batch_adaptive.call_args[0][0]
                assert len(call_args) == 2

    def test_scrape_transcripts_on_progress_callback(self) -> None:
        """Should call on_progress callback during fetching (lines 98-112)."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir) / "cases"
            cache_dir = Path(tmpdir) / "cache"
            term_dir = cases_dir / "2024"
            term_dir.mkdir(parents=True)
            case = {
                "oral_arguments": [
                    {"href": "https://example.com/oral/1", "unavailable": False}
                ],
                "opinion_announcements": [],
            }
            (term_dir / "22-123.json").write_text(json.dumps(case))

            with patch(
                "oyez_sa_asr.cli_scrape_transcripts.AdaptiveFetcher"
            ) as mock_fetcher_cls:
                mock_fetcher = mock_fetcher_cls.create.return_value
                mock_fetcher.fetch_batch_adaptive = AsyncMock(return_value=[])

                result = runner.invoke(
                    app,
                    [
                        "scrape",
                        "transcripts",
                        "--cases-dir",
                        str(cases_dir),
                        "--cache-dir",
                        str(cache_dir),
                    ],
                )

                assert result.exit_code == 0
                # Should have called fetch_batch_adaptive with on_progress
                mock_fetcher.fetch_batch_adaptive.assert_called_once()
                call_args = mock_fetcher.fetch_batch_adaptive.call_args
                # on_progress is passed as second positional argument
                assert len(call_args[0]) >= 2, (
                    "on_progress should be passed as positional arg"
                )
                assert callable(call_args[0][1]), (
                    "Second positional arg should be callable (on_progress)"
                )
                call_args[1] if len(call_args) > 1 else {}

    def test_build_case_map_skips_non_directories(self) -> None:
        """Should skip non-directory entries (lines 201, 203)."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            # Create a file (not a directory) in cases_dir
            (cases_dir / "not_a_dir.txt").write_text("test")

            # Create a valid term directory
            term_dir = cases_dir / "2024"
            term_dir.mkdir()
            case = {
                "term": "2024",
                "docket_number": "22-123",
                "oral_arguments": [
                    {"id": 123, "href": "https://example.com/audio.mp3"}
                ],
                "opinion_announcements": [],
            }
            (term_dir / "22-123.json").write_text(json.dumps(case))

            case_map = build_transcript_to_case_map(cases_dir)
            # Should only extract from valid directories, skip non-directories
            assert 123 in case_map
            assert case_map[123] == ("2024", "22-123")

    def test_build_case_map_handles_exceptions(self) -> None:
        """Should handle JSONDecodeError, KeyError, TypeError (lines 221-222)."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2024"
            term_dir.mkdir()

            # Create invalid JSON file
            (term_dir / "invalid.json").write_text("{ invalid json }")

            # Create file with missing keys
            incomplete = {"id": 1}  # Missing term, docket_number
            (term_dir / "incomplete.json").write_text(json.dumps(incomplete))

            # Create valid case file
            case = {
                "term": "2024",
                "docket_number": "22-123",
                "oral_arguments": [
                    {"id": 456, "href": "https://example.com/audio.mp3"}
                ],
                "opinion_announcements": [],
            }
            (term_dir / "valid.json").write_text(json.dumps(case))

            case_map = build_transcript_to_case_map(cases_dir)
            # Should handle exceptions gracefully and only extract from valid file
            assert 456 in case_map
            assert case_map[456] == ("2024", "22-123")
