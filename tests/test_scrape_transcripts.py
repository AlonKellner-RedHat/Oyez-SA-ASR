# Generated by Claude
"""Tests for scrape transcripts functionality."""

import json
import re
import tempfile
from pathlib import Path
from unittest.mock import AsyncMock, patch

from typer.testing import CliRunner

from oyez_sa_asr.cli import app
from oyez_sa_asr.scraper.parser_cases import extract_media_urls

runner = CliRunner()


def strip_ansi(text: str) -> str:
    """Remove ANSI escape codes from text."""
    return re.sub(r"\x1b\[[0-9;]*m", "", text)


class TestExtractMediaUrls:
    """Tests for extract_media_urls function."""

    def test_extracts_oral_arguments(self) -> None:
        """Should extract oral argument hrefs."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            case_data = {
                "oral_arguments": [
                    {"href": "https://example.com/oral/1", "unavailable": False},
                    {"href": "https://example.com/oral/2", "unavailable": False},
                ],
                "opinion_announcements": [],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert "https://example.com/oral/1" in urls
            assert "https://example.com/oral/2" in urls

    def test_extracts_opinion_announcements(self) -> None:
        """Should extract opinion announcement hrefs."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            case_data = {
                "oral_arguments": [],
                "opinion_announcements": [
                    {"href": "https://example.com/opinion/1", "unavailable": False},
                ],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert "https://example.com/opinion/1" in urls

    def test_skips_unavailable(self) -> None:
        """Should skip entries marked as unavailable."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            case_data = {
                "oral_arguments": [
                    {"href": "https://example.com/available", "unavailable": False},
                    {"href": "https://example.com/unavailable", "unavailable": True},
                ],
                "opinion_announcements": [],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert "https://example.com/available" in urls
            assert "https://example.com/unavailable" not in urls

    def test_handles_empty_cases_dir(self) -> None:
        """Should return empty list for empty directory."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            urls = extract_media_urls(cases_dir)
            assert urls == []

    def test_handles_multiple_terms(self) -> None:
        """Should collect URLs from multiple term directories."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)

            for term in ["2021", "2022"]:
                term_dir = cases_dir / term
                term_dir.mkdir()
                case_data = {
                    "oral_arguments": [
                        {
                            "href": f"https://example.com/{term}/oral",
                            "unavailable": False,
                        }
                    ],
                    "opinion_announcements": [],
                }
                (term_dir / "test.json").write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert len(urls) == 2
            assert "https://example.com/2021/oral" in urls
            assert "https://example.com/2022/oral" in urls

    def test_deduplicates_urls(self) -> None:
        """Should not return duplicate URLs."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir)
            term_dir = cases_dir / "2022"
            term_dir.mkdir()

            # Two cases with same oral argument
            for name in ["case1.json", "case2.json"]:
                case_data = {
                    "oral_arguments": [
                        {"href": "https://example.com/same", "unavailable": False}
                    ],
                    "opinion_announcements": [],
                }
                (term_dir / name).write_text(json.dumps(case_data))

            urls = extract_media_urls(cases_dir)
            assert urls.count("https://example.com/same") == 1


class TestScrapeTranscriptsCommand:
    """Tests for scrape transcripts CLI command."""

    def test_scrape_transcripts_help(self) -> None:
        """Should show help for scrape transcripts."""
        result = runner.invoke(app, ["scrape", "transcripts", "--help"])
        assert result.exit_code == 0
        output = strip_ansi(result.output)
        assert "--cases-dir" in output
        assert "--cache-dir" in output

    def test_scrape_transcripts_empty_cases(self) -> None:
        """Should handle empty cases directory gracefully."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir) / "cases"
            cases_dir.mkdir()
            cache_dir = Path(tmpdir) / "cache"

            result = runner.invoke(
                app,
                [
                    "scrape",
                    "transcripts",
                    "--cases-dir",
                    str(cases_dir),
                    "--cache-dir",
                    str(cache_dir),
                ],
            )

            assert result.exit_code == 0
            assert "No media URLs" in result.output or "0" in result.output

    def test_scrape_transcripts_fetches_urls(self) -> None:
        """Should fetch media URLs from processed cases."""
        with tempfile.TemporaryDirectory() as tmpdir:
            cases_dir = Path(tmpdir) / "cases"
            term_dir = cases_dir / "2022"
            term_dir.mkdir(parents=True)
            cache_dir = Path(tmpdir) / "cache"

            # Create a case file with media URLs
            case_data = {
                "oral_arguments": [
                    {"href": "https://example.com/oral/1", "unavailable": False}
                ],
                "opinion_announcements": [
                    {"href": "https://example.com/opinion/1", "unavailable": False}
                ],
            }
            (term_dir / "21-476.json").write_text(json.dumps(case_data))

            with patch(
                "oyez_sa_asr.cli_scrape_transcripts.AdaptiveFetcher"
            ) as mock_fetcher_cls:
                mock_fetcher = mock_fetcher_cls.create.return_value
                mock_fetcher.fetch_batch_adaptive = AsyncMock(return_value=[])

                result = runner.invoke(
                    app,
                    [
                        "scrape",
                        "transcripts",
                        "--cases-dir",
                        str(cases_dir),
                        "--cache-dir",
                        str(cache_dir),
                    ],
                )

                assert result.exit_code == 0
                # Should have called fetch_batch_adaptive with 2 URLs
                mock_fetcher.fetch_batch_adaptive.assert_called_once()
                call_args = mock_fetcher.fetch_batch_adaptive.call_args[0][0]
                assert len(call_args) == 2
