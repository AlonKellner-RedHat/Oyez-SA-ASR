{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flex Dataset Demo (v3.x)\n",
    "\n",
    "FLAC audio files + parquet metadata. Uses HuggingFace `datasets` v3.x with `trust_remote_code=True`.\n",
    "\n",
    "**Note**: This demo requires `datasets < 4.0`. For v4.x, use `demo_flex.ipynb` instead.\n",
    "\n",
    "*Generated by Claude*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check datasets version\n",
    "from oyez_sa_asr.hf_compat import datasets_version, supports_loading_scripts\n",
    "\n",
    "print(f\"datasets version: {datasets_version()}\")\n",
    "print(f\"Supports loading scripts: {supports_loading_scripts()}\")\n",
    "\n",
    "if not supports_loading_scripts():\n",
    "    print(\"\\nWARNING: You're on datasets v4.x. This demo uses v3.x features.\")\n",
    "    print(\"Please use demo_flex.ipynb instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3.x loading - recordings config\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds_rec = load_dataset(\"../datasets/flex\", \"recordings\", trust_remote_code=True)\n",
    "rec = ds_rec[\"train\"][0]\n",
    "\n",
    "print(f\"Recording: {rec['recording_id']}\")\n",
    "print(f\"Duration: {rec['duration_sec']:.1f}s\")\n",
    "print(f\"Sample rate: {rec['sample_rate']} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# Audio is automatically decoded\n",
    "audio = rec[\"audio\"]\n",
    "# Show first 10 seconds only (full recording can be long)\n",
    "end_sample = min(len(audio[\"array\"]), 10 * audio[\"sampling_rate\"])\n",
    "Audio(data=audio[\"array\"][:end_sample], rate=audio[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utterances with Segment Extraction (v3.x only)\n",
    "\n",
    "The `utterances` config extracts audio segments on-the-fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3.x loading - utterances config with automatic segment extraction\n",
    "ds_utt = load_dataset(\"../datasets/flex\", \"utterances\", trust_remote_code=True)\n",
    "utt = ds_utt[\"train\"][0]\n",
    "\n",
    "print(f\"Speaker: {utt['speaker_name']}\")\n",
    "print(f\"Text: {utt['text'][:80]}...\")\n",
    "print(f\"Duration: {utt['duration_sec']:.1f}s\")\n",
    "\n",
    "# Audio segment is pre-extracted by the loading script\n",
    "audio = utt[\"audio\"]\n",
    "Audio(data=audio[\"array\"], rate=audio[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v3.x Advantages\n",
    "\n",
    "With `trust_remote_code=True`, the `utterances` config:\n",
    "- Extracts audio segments on-the-fly\n",
    "- No need to manually call `extract_segment()`\n",
    "- Each row has the audio segment ready to use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
