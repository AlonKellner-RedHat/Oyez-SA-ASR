{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flex Dataset Demo (v4.x)\n",
    "\n",
    "FLAC audio files + parquet metadata. Uses HuggingFace `datasets` v4.x parquet auto-discovery.\n",
    "\n",
    "*Generated by Claude*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace v4.x loading (parquet auto-discovery)\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load recordings metadata\n",
    "ds_rec = load_dataset(\"../datasets/flex\", \"recordings\", streaming=True)\n",
    "rec = next(iter(ds_rec[\"train\"]))\n",
    "print(f\"Recording: {rec['recording_id']}\")\n",
    "print(f\"  Duration: {rec['duration_sec']:.1f}s\")\n",
    "print(f\"  Sample rate: {rec['sample_rate']} Hz\")\n",
    "\n",
    "# Load utterances metadata\n",
    "ds_utt = load_dataset(\"../datasets/flex\", \"utterances\", streaming=True)\n",
    "utt = next(iter(ds_utt[\"train\"]))\n",
    "print(\"\\nUtterance:\")\n",
    "print(f\"  Speaker: {utt['speaker_name']}\")\n",
    "print(f\"  Text: {utt['text'][:80]}...\")\n",
    "print(f\"  Duration: {utt['duration_sec']:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from oyez_sa_asr.loaders import extract_segment\n",
    "\n",
    "# Extract and play utterance segment using native loader\n",
    "audio_path = Path(\"../datasets/flex/audio\") / rec[\"audio_path\"]\n",
    "segment, sr = extract_segment(audio_path, utt[\"start_sec\"], utt[\"end_sec\"])\n",
    "\n",
    "print(f\"Playing segment: {utt['start_sec']:.1f}s - {utt['end_sec']:.1f}s\")\n",
    "Audio(data=segment, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Native Python Loader\n",
    "\n",
    "For segment extraction, use the native loader with `extract_segment()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oyez_sa_asr.loaders import load_flex\n",
    "\n",
    "# Native loader returns full lists\n",
    "recordings, utterances = load_flex()\n",
    "print(f\"Recordings: {len(recordings):,}\")\n",
    "print(f\"Utterances: {len(utterances):,}\")\n",
    "print(f\"Valid utterances: {sum(1 for u in utterances if u.get('valid', True)):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
