{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Oyez SA-ASR","text":"<p>Oyez project scraper, for the SA-ASR task</p>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Clone from source\ngit clone git://github.com/AlonKellner/oyez_sa_asr\ncd oyez_sa_asr\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>TODO</p>"},{"location":"#advanced-docs","title":"\ud83d\udcd6 Advanced docs","text":"<ul> <li>User Guide - Complete usage instructions</li> <li>Examples - Common use cases and examples</li> <li>ASR normalization findings - Transcript vs pronunciation   discrepancies and normalization strategies</li> <li>ASR normalization plan - Rules, precedence, flow,   multi-option output, and interruption handling</li> </ul>"},{"location":"asr_normalization_findings/","title":"ASR Normalization Findings","text":"<p>Edited by Cursor \u2013 February 2026</p> <p>Findings from human listening verification of Oyez oral-argument and opinion transcripts, used to design normalization rules so training text matches spoken pronunciation (e.g. for ASR). See scripts/collect_asr_artifacts.py for artifact collection and asr_normalization_plan.md for the normalization plan (rules, precedence, flow, multi-option output).</p>"},{"location":"asr_normalization_findings/#1-discrepancy-types","title":"1. Discrepancy types","text":"<p>Differences between original transcript text and actual audio pronunciation:</p> Category Original Heard Notes Case/docket ID 21-1164, 22-166, 13-1034 spoken in chunks (term + number) Not digit-by-digit. v. / vs. v. versus Consistent expansion. Title Mr. Mister Expansion. Years 2010, 1935 twenty ten, nineteen thirty five Spoken as years. Historical year 1215 twelve fifteen Year-like, not \u201cone thousand\u2026\u201d. Age / small number 94 ninety four Spoken as number. Currency $40,000, etc. forty thousand dollars, etc. Symbol + number \u2192 \u201cdollars\u201d. Section number (legal) Section 802, 802 Section Eight Oh Two Digit-style, \u201coh\u201d for zero. Acronyms BIA, USC Bee I Ay, You Ess Cee (21 USC) Spelled or letters. Acronym as word WOS Woes Some acronyms spoken as word, not letters. \u201cNo.\u201d (negation) No. I -- No. I -- Do not expand to \u201cnumber\u201d. \u201cNo.\u201d (number/citation) No. 96-511 number ninety six five eleven Expand to \u201cnumber\u201d when next token is citation. Unspoken section headers ORAL ARGUMENT OF JEFFREY W. McCOY (not spoken) Strip for ASR. Vote tally 9-0, 7-2 nine to zero, seven to two Separate from docket. Roman numeral VII, IV seven, fourth / Seventh Amendment Ordinal or spelled. Percentage 50% fifty percent Spoken form + \u201cpercent\u201d. Decade 1980s nineteen eighties Spoken form. Et al. et al. et al. or and others Optional expansion. Ordinal (word) Fifth, Eighth fifth, eighth Confirm consistency. Statute 21 U.S.C., Title 18 twenty one U S C, Title eighteen Explicit row."},{"location":"asr_normalization_findings/#11-unspoken-section-headers","title":"1.1 Unspoken section headers","text":"<p>Some transcript segments are section headers or labels that appear in the text but are not spoken in the audio. For example:</p> <ul> <li>ORAL ARGUMENT OF JEFFREY W. McCOY \u2013 appears at the start of a turn   after \u201cMr. McCoy.\u201d but is not read aloud; it is a structural header   (speaker/label).</li> <li>Similar patterns may include other \u201cORAL ARGUMENT OF \u2026\u201d, \u201cREBUTTAL OF \u2026\u201d,   or section titles embedded in turn text.</li> </ul> <p>Implication: For ASR training or alignment, these spans should be detected and either removed from the reference text or excluded from alignment so the model is not trained to \u201chear\u201d text that is not present in the audio. The artifact script or a separate pass could collect candidate patterns (e.g. \u201cORAL ARGUMENT OF\u201d, \u201cREBUTTAL OF\u201d, all-caps lines at turn boundaries) for review and stripping.</p>"},{"location":"asr_normalization_findings/#12-docket-number-grouping-for-normalization-logic","title":"1.2 Docket number grouping (for normalization logic)","text":"<p>Observed spoken patterns:</p> <ul> <li>21-1164 \u2192 \u201ctwenty one\u201d + \u201celeven sixty four\u201d (term + 4-digit block).</li> <li>22-166 \u2192 \u201ctwenty two\u201d + \u201cone sixty six\u201d (term + 3-digit block).</li> <li>13-1034 \u2192 \u201cthirteen\u201d + \u201cten thirty four\u201d (term + 4-digit block).</li> </ul> <p>First segment = term (spoken as a number); second segment = spoken by digit-group (e.g. 11\u201364, 1\u201366, 10\u201334), not as one integer. Vote-like patterns (e.g. 9-0, 7-2) are spoken as \u201cnine to zero\u201d, \u201cseven to two\u201d and should be normalized separately from docket numbers.</p>"},{"location":"asr_normalization_findings/#13-acronyms-pronounced-as-words","title":"1.3 Acronyms pronounced as words","text":"<p>Some acronyms are spoken as words (or word-like) rather than letter-by-letter:</p> <ul> <li>WOS (12-98, WOS v. EMA) \u2192 heard as \u201cWoes\u201d, not \u201cDouble-You Oh Ess\u201d.</li> <li>EMA in the same case \u2192 heard as \u201cEe Em Ay\u201d (letters). So same transcript   can mix word-style and letter-style acronyms.</li> </ul> <p>Strategy: Maintain an exception table for acronyms that are pronounced as words. Default for unknown ALL-CAPS tokens: spell out (B, I, A). For known word-pronunciation acronyms (e.g. WOS \u2192 Woes), substitute the spoken word. Extend the table as verification finds more (e.g. party names, agency nicknames). Optionally tag in artifact script: \u201cacronym_as_word\u201d for manual review.</p>"},{"location":"asr_normalization_findings/#2-strategies-to-handle-discrepancies","title":"2. Strategies to handle discrepancies","text":"Category Strategy Case IDs (docket) Term + docket by digit-groups; vote 9-0 \u2192 nine to zero. v. / vs. Literal substitution \u2192 \u201cversus\u201d (word-boundary safe). Mr. / Ms. / etc. Substitution table: Mr. \u2192 Mister, Ms. \u2192 Ms. or \u201cMiz\u201d, etc. Years (4-digit) 19xx/20xx \u2192 spoken year. 1xxx \u2192 year-like (e.g. twelve fifteen). Currency ($N) Detect <code>$</code> + number; convert to spoken form + \u201cdollars\u201d. Section N (legal) Year-like (1983) \u2192 nineteen eighty three; else (802) \u2192 Eight Oh Two. Acronyms (BIA, USC) Table for known acronyms; \u201c21 USC\u201d \u2192 twenty one U S C. Acronym-as-word (WOS, etc.) Exception table: spell-as-word; WOS \u2192 Woes, EMA \u2192 Ee Em Ay. \u201cNo.\u201d (negation) Leave as \u201cNo.\u201d when next token is word (I, The, Thank, etc.). \u201cNo.\u201d (number/citation) Expand to \u201cnumber\u201d when next token is citation (e.g. 96-511, 89-1416). Standalone numbers (ages) Two-digit in age-like context \u2192 spoken form (e.g. ninety four). Unspoken section headers Detect \u201cORAL ARGUMENT OF \u2026\u201d, all-caps labels; strip or exclude. Vote tally (9-0, 7-2) N-N \u2192 spoken numbers + \u201cto\u201d (nine to zero). Roman numeral (VII, IV) Context: ordinal (Seventh) or number (seven). Percentage (50%) Spoken form + \u201cpercent\u201d. Decade (1980s) Spoken form (nineteen eighties). Et al. Optional: \u201cand others\u201d or leave \u201cet al.\u201d. Ordinal (word) (Fifth, Eighth) Already word; confirm consistency. Statute citation (21 U.S.C., Title N) N USC \u2192 N + U S C; Title N \u2192 Title + spoken N."},{"location":"asr_normalization_findings/#3-new-insights-for-the-artifact-script","title":"3. New insights for the artifact script","text":"<p>Extend scripts/collect_asr_artifacts.py to collect:</p> Insight Suggestion Acronyms ALL-CAPS 2\u20135 letter tokens (BIA, USC, FBI); optionally \u201cN USC\u201d. Currency Pattern <code>\\$[\\d,]+</code>; report as own category (e.g. <code>currency</code>). Section vs year Tag \u201cSection\u201d + 4-digit: year-like (1983) vs other (802, 2255). Docket digit-length From case_ids, analyze second-segment length (2 vs 3 vs 4 digits). Historical 1xxx numbers Extend year collection to 1xxx (e.g. 1215, 1066); tag year-like. \u201cNo.\u201d context Record next token(s) to distinguish negation vs \u201cnumber\u201d. Unspoken headers Collect \u201cORAL ARGUMENT OF\u201d, \u201cREBUTTAL OF\u201d, all-caps at turn boundaries. Acronym-as-word Exception table (WOS \u2192 Woes); optionally tag acronyms pronounced as words. Vote tallies Separate from case_ids; pattern N-N (single digit\u2013single digit). Roman numerals Dedicated category (II\u2013XII); exclude single I. Percentages <code>\\d+%</code> or <code>\\d+ percent</code>; normalize for report. Decades Pattern: 19xxs / 20xxs (e.g. 1980s). Et al. <code>et\\s+al\\.?</code> \u2192 abbreviations. Word ordinals First\u2013Twelfth (word form) for Circuit/Amendment. Statute N U.S.C. / Title N Collect for citation normalization. Awareness Non-ASCII, mixed-case words, long all-caps, symbols: collect for awareness; no rule yet. Brackets (aaa), [aaa], {aaa}, 1) \u2014 e.g. [cough], [noise], (Inaudible); collect for awareness. Leading decimals .66, .5 \u2014 \"point six six\"; collect for awareness."},{"location":"asr_normalization_findings/#4-pronunciation-verification-reference","title":"4. Pronunciation verification reference","text":"<p>Unified table used for listening verification: what to verify, timestamps, raw cached MP3 path, and processed transcript path.</p> What to verify Start Stop MP3 file Transcript file versus, 21-1164 (argument) 0:00 0:06 21-1164_20221130-argument.delivery.mp3 2022/21-1164/oral_argument.json v., 21-1164 (opinion) 0:00 0:08 21-1164_20230328-opinion.delivery.mp3 2022/21-1164/opinion.json v., Eighth (22-166) 0:00 0:45 22-166_20230525-opinion.delivery.mp3 2022/22-166/opinion.json v. (13-1034 intro) 0:00 0:08 13-1034_20150601-opinion.delivery.mp3 2014/13-1034/opinion.json Section 802 (13-1034) 0:08 1:00 (same as above) (same) No. negation (21-1164) 55:06 55:07 21-1164_20221130-argument.delivery.mp3 2022/21-1164/oral_argument.json <p>MP3 dir: <code>.cache/audio/oyez.case-media.mp3/case_data/{term}/{docket}/</code>. Transcript dir: <code>data/transcripts/</code>. Paths relative to repo root. Timestamps in transcript JSON as <code>start</code>/<code>stop</code> (seconds); table uses MM:SS.</p>"},{"location":"asr_normalization_findings/#5-analysis-of-new-results-enhanced-script","title":"5. Analysis of new results (enhanced script)","text":"<p>After extending the artifact script with acronyms, currency, historical years, unspoken headers, and \u201cNo.\u201d context, a full run on <code>data/transcripts</code> reported:</p> <ul> <li>Acronyms: 3,179 unique; top include VII, III, EPA, ERISA, II, SEC,   FDA, EEOC, IRS, FCC, FBI, APA, BIA, USC (BIA 757, USC 340). Roman   numerals (II, III, IV, VI, VII, etc.) dominate; legal/agency acronyms   (BIA, USC, AEDPA, NLRB) are frequent.</li> <li>Currency: 2,437 unique; samples $10, $100, $1,000, $10,000,   $100,000. Normalization should expand to spoken form + \u201cdollars\u201d.</li> <li>Unspoken headers: 2 phrase types, \u201cORAL ARGUMENT OF\u201d and \u201cRESUMED   ORAL ARGUMENT OF\u201d. Confirm in audio that these spans are not spoken.</li> <li>no_dot_context: 2,863 unique next tokens; top samples \u201cI\u201d, \u201cThe\u201d,   \u201cNo,\u201d, \u201cBut\u201d, \u201cIt\u201d. \u201cNo. I\u201d / \u201cNo. The\u201d etc. indicate negation; \u201cNo.   96-511\u201d style (next token numeric) indicates citation \u2192 expand to   \u201cnumber\u201d.</li> <li>Historical years: 886 unique (e.g. 1331, 1292, 1866, 1871). Treat   as year-like for pronunciation (\u201ctwelve fifteen\u201d, \u201ceighteen sixty six\u201d).</li> </ul> <p>Notable: \u201cNo.\u201d next-token distribution supports disambiguation (next word \u201cI\u201d/\u201cThe\u201d/\u201cBut\u201d vs \u201c96-511\u201d/\u201c89-1416\u201d). Unspoken headers are rare but must be stripped for alignment.</p>"},{"location":"asr_normalization_findings/#51-new-categories-post-expansion","title":"5.1 New categories (post-expansion)","text":"<p>The script now also reports: vote_tally (9-0, 7-2; separate from case_ids), roman_numerals (II\u2013XII), percentages, decades, ordinals_word (Fifth, Seventh, etc.), statute_citation (21 U.S.C., Title N), and awareness categories awareness_non_ascii, awareness_mixed_case, awareness_all_caps_long, awareness_symbols (for unestablished rules; report-only). Rule-candidate categories: leading_decimal, non_speech_brackets, editorial_square_bracket, dash_range, ellipsis, structural_bracket, numbered_list_marker.</p>"},{"location":"asr_normalization_findings/#52-artifact-run-analysis-latest-run","title":"5.2 Artifact run analysis (latest run)","text":"<p>Summary from a full run on <code>data/transcripts</code> (as of February 2026). Edited by Cursor.</p> <p>New verification rules (unverified):</p> <ul> <li>vote_tally: 17+ unique tokens; samples 9-0, 7-2, 5-4, 6-1, 4-1 (single digit\u2013single digit).</li> <li>roman_numerals: VII (4564), III (4161), II (2776), X (2369), IV (945), V, IX, VI, XI, VIII, XII.</li> <li>percentages: 50%, 100%, 10%, 5%, 25%, 20%, 90%, 1%, etc.; also \u201cN percent\u201d form.</li> <li>decades: 1970s (193), 1930s (160), 1950s (150), 1960s (134), 1920s (96), 1980s (92), 1990s (68), 1900s (37), 2000s (15).</li> <li>ordinals_word: first/second/third (most frequent), Fifth, Ninth, Fourth, Seventh, Eighth, Eleventh, Tenth, Twelfth (and lowercase variants).</li> <li>statute_citation: 18 U.S.C., 28 U.S.C., Title 7, Title 18, 42 U.S.C., Title 28, Title 9, 21 U.S.C., etc.</li> </ul> <p>Potential future rules (awareness):</p> <ul> <li>awareness_non_ascii: U+2019 (right single quote, 78,572), U+201C/U+201D (curly quotes), U+2013 (en dash), U+2026 (ellipsis), U+2014 (em dash), U+2018, and others (accents, \u00a7, etc.). Collected for awareness only; no verification rule yet.</li> <li>awareness_mixed_case: LaGuardia, McCarran, McDonald, McDonnell, McConnell, TikTok, McCoy, etc.</li> <li>awareness_all_caps_long: CERCLA, RLUIPA, MOHELA, IIRIRA, EMTALA, ASARCO, ANILCA, HEROES, and many 6+ letter all-caps tokens.</li> <li>awareness_symbols: \u201c...\u201d (160,801), U+2013 (en dash), U+2026 (ellipsis), U+2014 (em dash).</li> <li>Brackets (awareness): Different bracket types and usages \u2014 (parens) (Inaudible) (35,066), (a)/(b)/(c) (subpoints), (Voice Overlap), (1)/(2) (numbered), (Laughter.); [square] [Laughter] (7,415), [Inaudible] (6,153), [Voice Overlap], [coughing], [Recess], [dollars], [noise]-style; {curly} rare ({Voice overlap}, {b}); numbered 1) 2) 3) (6,556 / 5,849 / 3,670). Many are non-speech labels (e.g. [cough], [noise]) or structural (1) 2)); normalize or strip for ASR.</li> <li>Leading decimals (awareness): .2 (380), .5 (54), .1 (40), .66, .38, .22 \u2014 pronounced \"point two\", \"point six six\", etc. Normalize to spoken form for ASR.</li> </ul> <p>Potential future rules (from awareness categories): see \u00a75.3 for the nine formalized rule candidates (examples and strategy). Prioritization: leading decimals and bracket non-speech strip first (Round 7); then structural brackets and editorial [= X]; then Unicode/symbols; mixed-case/long all-caps as exceptions. No verification rule or Round N table yet.</p>"},{"location":"asr_normalization_findings/#53-potential-future-rules-from-awareness-formalized-candidates","title":"5.3 Potential future rules (from awareness) \u2014 formalized candidates","text":"<p>Each awareness check maps to at least one new potential future rule to add (currently missing). Representative examples and the rule to formalize:</p> <ul> <li>awareness_non_ascii \u2014 Examples: U+2019 (78,572), U+201C/U+201D (28,820 /   27,167), U+2013 (5,485), U+2026 (1,143), U+2014 (999), U+00A7 (299), U+00BD   (36), accents (U+00E0, U+00E9).   Rule: Unicode \u2192 spoken/ASCII: curly quotes \u2192 straight; U+2019 \u2192   apostrophe; en/em dash \u2192 hyphen or \u201cto\u201d in ranges; \u00a7 \u2192 \u201csection\u201d when   standalone; \u00bd \u2192 \u201cone half\u201d; ellipsis \u2192 omit or pause; accents keep or map to   ASCII.</li> <li>awareness_mixed_case \u2014 Examples: LaGuardia (825), McCarran (647), McDonald   (584), McDonnell (498), McConnell (395), TikTok (170), McCoy (159), YouTube   (122), FedEx (47), PhD (22), DeKalb (96), DuPoint (73). Rule: Mixed-case   token pronunciation: Mc/Mac/De/La/Di prefix names \u2192 rule or table (e.g. \u201cMcX\u201d   \u2192 \u201cMc\u201d + name); brands/abbrev (TikTok, FedEx, PhD, YouTube) \u2192 exception table   (word vs letters). Verify 1\u20132 per pattern.</li> <li>awareness_all_caps_long \u2014 Examples: CERCLA (296), RLUIPA (196), MOHELA   (180), EMTALA (171), ASARCO (165); JUSTICE (37), ARGUMENT (34), ILLEGIBLE   (21); XXVIII (27), XXXIII (12); PETITIONERS (9), ROBERTS (7). Rule: Long   all-caps disambiguation: (1) Known statute/agency acronym (6+ letters) \u2192   acronym table or spell-out; (2) plain English word in all-caps (JUSTICE,   ARGUMENT, ILLEGIBLE) \u2192 label/header: strip or lowercase; (3) Roman (XXVIII) \u2192   reuse roman numeral rule.</li> <li>awareness_symbols \u2014 Examples: \u201c...\u201d (160,801), U+2013 (5,033), U+2026   (1,137), U+2014 (968). Rule: Ellipsis and dashes for speech: ellipsis   (literal \u201c...\u201d or U+2026) \u2192 omit or brief pause for ASR; en/em dash in \u201cN\u2013M\u201d   ranges \u2192 \u201cN to M\u201d (e.g. 2010\u20132015 \u2192 twenty ten to twenty fifteen); elsewhere \u2192   hyphen or \u201cand\u201d.</li> <li>awareness_brackets_parens \u2014 Examples: (Inaudible) 35,066, (a)/(b)/(c)   16k/16k/8k, (Voice Overlap) 13k, (1)/(2) 6k/5k, (Laughter.) 1,842, (ph) 1,332,   (Coughing), (Audio Cut), (Colorado Revised Statutes). Rule: Parens: (1)   Strip non-speech \u2014 (Inaudible), (Voice Overlap), (Laughter.), (Coughing),   (ph), (Audio Cut), typos (Inauidble); (2) structural (a)(b)(c), (1)(2) if   spoken \u2192 normalize to \u201ca\u201d/\u201cone\u201d etc. (verify); (3) content (Section 102),   (Articles V and VI) \u2192 may be spoken; normalize inner text.</li> <li>awareness_brackets_square \u2014 Examples: [Laughter] 7,415, [Inaudible] 6,153,   [Voice Overlap] 433, [Recess] 30, [dollars] 26, [coughing] 5; [= Mr.], [=   VII], [= 1983], [= 10:00]; [Ginsburg: So you make]. Rule: Square brackets:   (1) Strip non-speech ([Laughter], [Inaudible], [Voice Overlap], [Recess],   [coughing], [dollars]); (2) editorial [= X] \u2192 replace with normalized form of   X (e.g. [= Mr.] \u2192 Mister, [= 1983] \u2192 nineteen eighty three), then strip; (3)   speaker [Name: ...] \u2192 strip or keep for diarization.</li> <li>awareness_brackets_curly \u2014 Examples: {Voice overlap} 1, {b} 1. Rule:   Same as parens: strip non-speech labels; if structural {b} \u2192 \u201cb\u201d if spoken.   Rare; fold into bracket-strip rule.</li> <li>awareness_brackets_numbered \u2014 Examples: 1) 6,556, 2) 5,849, 3) 3,670 \u2026 10)   211, 27) 56; 1970) 2, 1932) 1 (year false positives). Rule: Numbered list   marker \u201cN)\u201d: at clause start, \u201c1) 2) 3)\u201d \u2192 speak as \u201cone\u201d/\u201ctwo\u201d/\u201cthree\u201d (or   \u201cfirst\u201d etc.; verify). Exclude when \u201cN)\u201d is year+paren (e.g. 1970)) via   context.</li> <li>awareness_leading_decimal \u2014 Examples: .2 (380), .5 (54), .1 (40), .38   (21), .22 (14), .66 (2), .1983 (1 false positive). Rule: Leading decimal   \u201c.N\u201d: pronounce \u201cpoint\u201d + digit sequence (.2 \u2192 \u201cpoint two\u201d, .66 \u2192 \u201cpoint six   six\u201d). Exclude .YYYY (year) by context.</li> </ul> <p>Prioritization for verification and implementation: leading decimals and bracket   non-speech strip first (Round 7); then structural brackets and editorial [=   X]; then Unicode/symbols; mixed-case/long all-caps as exceptions. Edited by   Cursor.</p>"},{"location":"asr_normalization_findings/#6-round-2-verification-examples-for-new-artifact-types","title":"6. Round 2: verification examples for new artifact types","text":"<p>Unified table for listening verification of new artifact types. Use only transcripts with cached MP3 under <code>.cache/audio/oyez.case-media.mp3/...</code>.</p> What to verify Start Stop MP3 file Transcript file Unspoken header (ORAL ARGUMENT OF \u2026 not spoken) 0:00 0:06 21-1164_20221130-argument.delivery.mp3 oral_argument.json Currency, historical years, age (22-166) 0:00 2:20 22-166_20230525-opinion.delivery.mp3 opinion.json Acronyms BIA, Section 802, 21 USC (13-1034) 0:08 1:30 13-1034_20150601-opinion.delivery.mp3 opinion.json <ul> <li>Unspoken header: Turn 0 in 21-1164 argument (0.31\u20135.82 s) contains   \u201cORAL ARGUMENT OF JEFFREY W. McCOY\u201d after \u201cMr. McCoy.\u201d Confirm only   \u201cWe'll hear argument \u2026 Mr. McCoy.\u201d is spoken.</li> <li>Currency / historical years / age: 22-166 opinion (one long turn   0\u2013140 s). Note how \u201c$40,000\u201d, \u201c$15,000\u201d, \u201c$25,000\u201d, \u201c1215\u201d, \u201c1935\u201d,   \u201c94\u201d are pronounced.</li> <li>Acronyms / Section 802: 13-1034 opinion turn 1 (from 7.82 s) has   \u201cBIA\u201d, \u201cSection 802\u201d, \u201c21 USC\u201d, \u201cEighth Circuit\u201d. Confirm BIA \u2192 \u201cBee I   Ay\u201d, Section 802 \u2192 \u201cSection Eight Oh Two\u201d, 21 USC \u2192 \u201ctwenty one U S C\u201d.</li> </ul> <p>MP3 dir and transcript dir as in section 4. Timestamps in JSON as <code>start</code>/<code>stop</code> (seconds).</p>"},{"location":"asr_normalization_findings/#61-verification-coverage-rules-and-instance-count","title":"6.1 Verification coverage: rules and instance count","text":"<p>Goal: at least two verified instances per rule (utterances may overlap).</p> Rule Verified instances Source clips Case/docket ID 4 21-1164 arg+opin, 22-166, 13-1034 v. / vs. 4 same Title (Mr. / Ms.) 2 21-1164 arg, 20-1650 arg (Round 3) Years (19xx/20xx) 2 22-166, 20-1650 arg (Round 3) Historical year (1xxx) 2 22-166 (1215), 72-6041 arg (1791) (Round 5) Age / small number 2 22-166 (94), 12-98 (12 and 18 hours) (Round 4) Currency 2 22-166, 12-98 ($42M, $2.8M) (Round 4) Section number (legal) 2 13-1034 (802), 20-1650 arg (404, 2 and 3) (Round 3) Acronyms (BIA, USC, etc.) 2 13-1034 (BIA, USC), 20-1650 arg (U.S.C., Section 404) (Round 3) \u201cNo.\u201d (negation) 2 21-1164 arg, 20-1650 arg \u201cNo. Thank you.\u201d (Round 3) \u201cNo.\u201d (number/citation) 2 96-511, 12-98 (Round 4) Unspoken section headers 2 21-1164 arg, 20-1650 arg (Round 3) Vote tally (9-0, 7-2) 2 1958/290, 1964/48 (Round 6) Roman numeral (VII, IV) 2 72-6041 arg (Seventh), 96-511 (V-chip\u2192Vee) (Round 6) Percentage (50%) 2 72-6041 (97%), 96-511 (70%) (Round 6) Decade (1980s) 2 21-869 (1960s\u2192nineteen sixties) (Round 6) Ordinal (word) (Fifth, Eighth) 2 72-6041 (Seventh Amendment) (Round 6) Statute citation (21 U.S.C., Title N) 2 72-6041, 20-1650 (Round 6) <p>Rules above now have at least two verified instances. See \u00a76.11 for exceptions and multiple solutions (e.g. N-N, v., Roman vs acronym). Awareness categories (non-ASCII, mixed-case, long all-caps, symbols, brackets, leading decimals) are report-only; \u00a75.3 lists nine formalized potential future rules and prioritization (Round 7). Round 6 listener transcriptions in \u00a76.10. Use <code>scripts/collect_asr_artifacts.py --need-verification</code> to re-check.</p>"},{"location":"asr_normalization_findings/#62-round-3-additional-clips-for-second-instances","title":"6.2 Round 3: additional clips for second instances","text":"<p>Clips below give a second verified instance for the rules in the table above. All use cached MP3 under <code>.cache/audio/oyez.case-media.mp3/...</code>.</p> What to verify Start Stop MP3 file Transcript file Unspoken header, Mr., case ID, v. (20-1650) 0:00 0:10 20-1650_20220119-argument.delivery.mp3 oral_argument.json No. negation \u201cNo. Thank you.\u201d (20-1650) 29:51 29:53 (same as above) (same) Section 404, year 2010 (20-1650) 35:02 37:13 (same as above) (same) <ul> <li>Intro (0:00\u20130:10): Turn 0 has \u201cWe'll hear argument next in Case   20-1650, Concepcion versus United States. Mr. McCloud. ORAL ARGUMENT   OF CHARLES L. McCLOUD\u201d \u2014 confirm case ID \u2192 \u201ctwenty sixteen fifty\u201d,   v. \u2192 \u201cversus\u201d, Mr. \u2192 \u201cMister\u201d, and that \u201cORAL ARGUMENT OF \u2026\u201d is not   spoken.</li> <li>No. Thank you. (29:51\u201329:53): Second instance for \u201cNo.\u201d (negation);   do not expand to \u201cnumber\u201d.</li> <li>Section 404, 2010 (35:02\u201337:13): Government counsel; \u201cSection 404\u201d,   \u201cSections 2 and 3\u201d, \u201csince 2010\u201d \u2014 second instance for section number   and for year. Same file also contains \u201c18 U.S.C. 3582\u201d later for a   second acronym (U.S.C.) instance; use transcript to locate exact turn.</li> </ul>"},{"location":"asr_normalization_findings/#63-round-2-listener-transcriptions-from-verification","title":"6.3 Round 2 listener transcriptions (from verification)","text":"<p>Listener verification from the Round 2 clips, documenting original transcript vs heard (audio pronunciation).</p> <p>1. Unspoken header \u2014 21-1164 argument (0:00\u20130:06)</p> Original Heard We'll hear argument this morning in Case 21-1164, Wilkins versus the United States. Mr. McCoy. ORAL ARGUMENT OF JEFFREY W. McCOY We'll hear argument this morning in Case twenty one eleven sixty four, Wilkins versus the United States. Mister McCoy. <p>(\u201cORAL ARGUMENT OF JEFFREY W. McCOY\u201d is not spoken; header only in text.)</p> <p>2. Case ID in opinion \u2014 21-1164 opinion</p> Original Heard Jutice Sotomayor has the opinion of the Court this morning in case 21-1164 Wilkins v. United States. Jutice Sotomayor has the opinion of the Court this morning in case twenty one eleven sixty four Wilkins versus United States. <p>3. Currency, years, age \u2014 22-166 opinion (0:00\u20132:20)</p> Original Heard \u2026 in case 22-166, Tyler v. Hennepin County. \u2026 In 2010, Geraldine Tyler, who's now 94, \u2026 The home sold for $40,000. Tyler owed only $15,000 \u2026 the extra $25,000 \u2026 Magna Carta in 1215. \u2026 the law in 1935. \u2026 in case twenty two one sixty six, Tyler versus Hennepin County. \u2026 In twenty ten, Geraldine Tyler, who's now ninety four, \u2026 The home sold for forty thousand dollars. Tyler owed only fifteen thousand dollars \u2026 the extra twenty five thousand dollars \u2026 Magna Carta in twelve fifteen. \u2026 the law in nineteen thirty five. <p>4. Case ID intro \u2014 13-1034 opinion</p> Original Heard Justice Ginsburg has our opinion this morning in case 13-1034 Mellouli v. Lynch. Justice Ginsburg has our opinion this morning in case thirteen ten thirty four Mellouli versus Lynch. <p>5. Acronyms and section numbers \u2014 13-1034 opinion (0:08\u20131:30)</p> Original Heard The Board of Immigration Appeals (BIA) affirmed \u2026 Section 802 of Title 21. \u2026 as defined in 21 USC Section 802. \u2026 Section 802 limits \u2026 Section Eight Oh Two. \u2026 the BIA has \u2026 Section 802. The Board of Immigration Appeals, of Bee I Ay, affirmed \u2026 Section Eight Oh Two of Title twenty one. \u2026 twenty one You Ess Cee Section Eight Oh Two. \u2026 Section Eight Oh Two limits \u2026 Section Eight Oh Two. \u2026 the Bee I Ay has \u2026 Section Eight Oh Two. <p>6. \u201cNo.\u201d (negation) \u2014 21-1164 argument</p> Original Heard No. I -- No. I -- <p>(No expansion to \u201cnumber\u201d; negation context.)</p>"},{"location":"asr_normalization_findings/#64-round-3-listener-transcriptions-from-verification","title":"6.4 Round 3 listener transcriptions (from verification)","text":"<p>Listener verification from the Round 3 clips (20-1650 argument), documenting original transcript vs heard (audio pronunciation).</p> <p>1. Unspoken header, Mr., case ID, v. \u2014 20-1650 argument (0:00\u20130:10)</p> Original Heard We'll hear argument next in Case 20-1650, Concepcion versus United States. Mr. McCloud. ORAL ARGUMENT OF CHARLES L. McCLOUD We'll hear argument next in Case twenty sixteen fifty, Concepcion versus United States. Mister McCloud. <p>(\u201cORAL ARGUMENT OF CHARLES L. McCLOUD\u201d is not spoken; case ID spoken \u201ctwenty sixteen fifty\u201d; Mr. \u2192 Mister.)</p> <p>2. \u201cNo.\u201d (negation) \u2014 20-1650 argument</p> Original Heard No. Thank you. No. Thank you. <p>(No expansion to \u201cnumber\u201d; negation context.)</p> <p>3a. Section 404, year 2010, Section 3553(a) \u2014 20-1650 argument (35:02\u201337:13)</p> Original Heard Section 404 \u2026 Sections 2 and 3 \u2026 since 2010 \u2026 Section 404(c) \u2026 Section 3553(a) \u2026 Section Four Oh Four \u2026 Sections Two and Three \u2026 since twenty ten \u2026 Section Four Oh Four Cee \u2026 Section thirty five fifty three Ay \u2026 <p>(Section 404 \u2192 \u201cSection Four Oh Four\u201d; 2010 \u2192 \u201ctwenty ten\u201d; 75 \u2192 \u201cseventy five\u201d; 3553(a) \u2192 \u201cthirty five fifty three Ay\u201d; 404(c) \u2192 \u201cFour Oh Four Cee\u201d.)</p> <p>3b. 18 U.S.C. 3582(c)(1)(A), acronym U.S.C. \u2014 20-1650 argument</p> Original Heard 18 U.S.C. 3582(c)(1)(A). 3582(c) \u2026 (c)(1)(A) \u2026 (c)(2) \u2026 (c)(1)(B) \u2026 Rule 35 \u2026 3553(a) \u2026 3582(c)(1)(B) \u2026 Eighteen You Ess Cee thirty five eighty two Cee One Ay. thirty five eighty two Cee \u2026 Cee One Ay \u2026 Cee Two \u2026 Cee One Bee \u2026 Rule thirty five \u2026 thirty five fifty three Ay \u2026 thirty five eighty two Cee One Bee \u2026 <p>(18 U.S.C. \u2192 \u201cEighteen You Ess Cee\u201d; 3582(c)(1)(A) \u2192 \u201cthirty five eighty two Cee One Ay\u201d; (c)(1)(B) \u2192 \u201cCee One Bee\u201d; Rule 35 \u2192 \u201cRule thirty five\u201d.)</p>"},{"location":"asr_normalization_findings/#65-round-4-clips-to-clarify-by-listening","title":"6.5 Round 4: clips to clarify by listening","text":"<p>Goal: get at least two verified instances for \"No.\" (number/citation). Table below listed candidate clips with cached MP3s; verified in Round 4.</p> What to verify Start Stop MP3 file Transcript file \"No.\" (number) 96-511 0:00 0:10 mp3 opinion \"No.\" (number) 12-98 0:00 0:15 mp3 opinion <ul> <li>96-511 (0:00\u20130:10): Turn 0: \"The opinion of the Court in No. 96-511, Reno   versus American Civil Liberty Union will be announced by Justice Stevens.\"   Confirm \"No.\" \u2192 number (e.g. \"number ninety six five eleven\").</li> <li>12-98 (0:00\u20130:15): Turn 0: \"The second case is No. 12-98, WOS versus EMA.\"   Confirm \"No.\" \u2192 number (e.g. \"number twelve ninety eight\").</li> </ul> <p>Currency and age reached 2 instances via 12-98 (Round 4). Round 5 targets historical year (1xxx) only (see \u00a76.7).</p>"},{"location":"asr_normalization_findings/#66-round-4-listener-transcriptions-from-verification","title":"6.6 Round 4 listener transcriptions (from verification)","text":"<p>Listener verification from the Round 4 clips, documenting original transcript vs heard (audio pronunciation).</p> <p>1. \u201cNo.\u201d (number/citation) \u2014 96-511 opinion (0:00\u20130:10)</p> Original Heard The opinion of the Court in No. 96-511, Reno versus American Civil Liberty Union will be announced by Justice Stevens. The opinion of the Court in Number Ninety Six Five Eleven, Reno versus American Civil Liberty Union will be announced by Justice Stevens. <p>(\u201cNo. 96-511\u201d \u2192 \u201cNumber Ninety Six Five Eleven\u201d; confirms expand to \u201cnumber\u201d when next token is citation.)</p> <p>2. \u201cNo.\u201d (number/citation), WOS, EMA, currency \u2014 12-98 opinion (0:00\u2013opening)</p> Original Heard The second case is No. 12-98, WOS versus EMA. \u2026 $42 million \u2026 $2.8 million \u2026 12 and 18 hours \u2026 E. M. A. \u2026 The second case is number Twelve Ninety Eight, Woes versus Ee Em Ay. \u2026 Forty Two million Dollars \u2026 Two Point Eight million Dollars \u2026 Twelve and Eighteen hours \u2026 Ee Em Ay. \u2026 <p>(\u201cNo. 12-98\u201d \u2192 \u201cnumber Twelve Ninety Eight\u201d. WOS \u2192 \u201cWoes\u201d (word, not letter-by-letter). EMA \u2192 \u201cEe Em Ay\u201d (letters). Currency and numbers as spoken.)</p>"},{"location":"asr_normalization_findings/#67-round-5-clips-for-historical-year-1xxx-second-instance","title":"6.7 Round 5: clips for historical year (1xxx) \u2014 second instance","text":"<p>Goal: get a second verified instance for historical year (1xxx). Achieved in Round 5 (72-6041 argument). Table below listed the clip; listener transcriptions in \u00a76.8.</p> What to verify Start Stop MP3 file Transcript file Historical year \u201c1791\u201d (72-6041 arg) 4:06 4:24 19740219a_72-6041\u2026 72-6041 oral_arg <ul> <li>72-6041 argument (4:06\u20134:24): Turn 11: \u201c1791\u201d \u2192 \u201cseventeen ninety one\u201d   (verified \u00a76.8). Same file: \u201cin England in 1791\u201d in later turn (verified \u00a76.8).</li> </ul>"},{"location":"asr_normalization_findings/#68-round-5-listener-transcriptions-from-verification","title":"6.8 Round 5 listener transcriptions (from verification)","text":"<p>Listener verification from the Round 5 clip (72-6041 argument), documenting original transcript vs heard (audio pronunciation) for historical year (1xxx).</p> <p>1a. Historical year \u201c1791\u201d \u2014 72-6041 argument (4:06\u20134:24)</p> Original Heard No, Your Honor. We're not at all asking that, but the rule seems to be clear that the tenant could assert the counterclaim in the possessory action. If the counterclaim is one which arises, one which would be tried by jury in 1791, then -- No, Your Honor. We're not at all asking that, but the rule seems to be clear that the tenant could assert the counterclaim in the possessory action. If the counterclaim is one which arises, one which would be tried by jury in seventeen ninety one, then -- <p>(\u201c1791\u201d \u2192 \u201cseventeen ninety one\u201d; year-like pronunciation.)</p> <p>1b. Historical year \u201cin England in 1791\u201d \u2014 72-6041 argument</p> Original Heard And our point is that in England in 1791, which was the critical date for application of the Seventh Amendment -- And our point is that in England in seventeen ninety one, which was the critical date for application of the Seventh Amendment -- <p>(\u201c1791\u201d \u2192 \u201cseventeen ninety one\u201d; confirms 1xxx historical years spoken as year-like, not \u201cone thousand seven hundred ninety one\u201d.)</p>"},{"location":"asr_normalization_findings/#69-round-6-clips-for-new-rules-vote-tally-roman-numeral-percentage-decade-ordinal-word-statute","title":"6.9 Round 6: clips for new rules (vote tally, Roman numeral, percentage, decade, ordinal word, statute)","text":"<p>Goal: get at least two verified instances for vote tally, Roman numeral, percentage, decade, ordinal (word), and statute citation. Table below lists candidate clips with cached MP3s; listener transcriptions in \u00a76.10 after listening.</p> What to verify Start Stop MP3 file Transcript file Vote 1958/290 28:10 28:39 mp3 oral_arg Vote 1964/48 104:57 105:21 mp3 oral_arg Roman 1964/48 6:51 8:12 mp3 oral_arg Roman V 96-511 28:29 28:32 mp3 oral_arg Pct 72-6041 19:43 20:12 mp3 oral_arg Pct 96-511 56:01 56:08 mp3 oral_arg Decade 21-869 83:32 83:51 mp3 oral_arg Ordinal 72-6041 7:28 10:22 mp3 oral_arg Statute 72-6041 29:01 33:36 mp3 oral_arg Statute 20-1650 50:56 52:46 mp3 oral_arg <ul> <li>1958/290 (28:10\u201328:39): Vote tally; N-N \u2192 spoken numbers + \u201cto\u201d (e.g. nine to zero).</li> <li>1964/48 (104:57\u2013105:21): Second vote-tally; turn 3 (6:51\u20138:12)   Sect. 7 and 8 (Roman/ordinal).</li> <li>96-511 (28:29\u201328:32): \u201cV-chip\u201d \u2192 Roman \u201cV\u201d; (56:01\u201356:08) \u201c70 percent\u201d \u2192   seventy percent.</li> <li>72-6041 (19:43\u201320:12): \u201c97%\u201d \u2192 ninety seven percent; (7:28\u201310:22) Seventh   Am.; (29:01\u201333:36) statute.</li> <li>20-1650 (50:56\u201352:46): \u201c18 U.S.C. 3582(c)(1)(A)\u201d \u2192 eighteen U S C thirty   five eighty two.</li> <li>21-869 (83:32\u201383:51): \u201cafter the 1960s\u201d \u2192 nineteen sixties.</li> </ul>"},{"location":"asr_normalization_findings/#610-round-6-listener-transcriptions-from-verification","title":"6.10 Round 6 listener transcriptions (from verification)","text":"<p>Listener verification from the Round 6 clips, documenting original transcript vs heard (audio pronunciation) for vote tally, Roman numeral, percentage, decade, ordinal (word), statute citation, and related patterns (document IDs, number ranges, acronyms). Edited by Cursor.</p> <p>1) Document identifier (not a vote tally)</p> Original Heard Mr. McDonald \u2026 SEC docket number -- number 818-105-1-2, United Fund EALIC sales kit pages 613 and 614. Mister McDonald \u2026 Ess Ee Cee docket number -- number Eight Eighteen Dash One Oh Five Dash One Dash Two, United Fund Ealik sales kit pages Six Thirteen and Fourteen. <p>(SEC \u2192 Ess Ee Cee; docket 818-105-1-2 spoken digit/dash style; 613 and 614 \u2192 Six Thirteen and Fourteen; EALIC \u2192 Ealik.)</p> <p>2) Number range (not a vote tally)</p> Original Heard It has 6-8 employees. It has six to eight employees. <p>(N-M as range \u2192 \u201cN to M\u201d when not a vote or docket.)</p> <p>3) Acronym N.O.V. (not Roman numeral)</p> Original Heard \u2026 $93,000 \u2026 $55,000 \u2026 verdict $93,000. Now all motion N.O.V. or for new trial \u2026 \u2026 Ninety Three Thousand Dollars \u2026 Fifty Five Thousand Dollars \u2026 verdict Ninety Three Thousand Dollars. Now all motion En Oh Vee or for new trial \u2026 <p>(N.O.V. \u2192 En Oh Vee; dollar amounts \u2192 spoken form. Quote marks: \u201c\\u201c\u2026\\u201d\u201d in transcript \u2192 \u201cand I quote \u2026 Close the quote\u201d in audio.)</p> <p>4) Acronym V-chip (not Roman numeral)</p> Original Heard --Congress... that would essentially be the mandated V-chip option. --Congress... that would essentially be the mandated Vee chip option. <p>(V-chip \u2192 Vee chip.)</p> <p>5) Large number and percentage</p> Original Heard the 122,000 figure \u2026 97% of those cases the Hundred And Twenty Two Thousand figure \u2026 Ninety Seven Percent of those cases <p>6) Percent (no symbol; explicit \u201cpercent\u201d in transcript)</p> Original Heard But if 70 percent is shielded and 30 percent isn't But if Seventy percent is shielded and Thirty percent isn't <p>(Numbers before \u201cpercent\u201d still spoken as words.)</p> <p>7) Decade</p> Original Heard after the 1960s, when he was sued after the Nineteen Sixties, when he was sued <p>8) Page, years, case names (v. \u2192 Vee), ordinals</p> Original Heard Our main brief at page 7 \u2026 Capital Traction versus Hof decided in 1899 \u2026 in England in 1791 \u2026 Since 1830 \u2026 Ross v. Bernhard in 1970 \u2026 Parsons v. Bedford \u2026 Dairy Queen v. Wood \u2026 Whitehead v. Shattuck \u2026 Our main brief at page Seven \u2026 Capital Traction versus Hof decided in Eighteen Ninety Nine \u2026 in England in Seventeen Ninety One \u2026 Since Eighteen Thirty \u2026 Ross Vee Bernhard in Nineteen Seventy \u2026 Parsons Vee Bedford \u2026 Dairy Queen Vee Wood \u2026 Whitehead Vee Shattuck \u2026 <p>(Standalone \u201cversus\u201d kept; \u201cv.\u201d in case names \u2192 Vee. Years and page number \u2192 spoken form.)</p> <p>9) Years, statute/code, \u201c12 men\u201d, \u201c122,000\u201d, \u201c13702\u201d, \u201c600-somewhat\u201d, \u201cpage 19\u201d, typo</p> Original Heard in 1864 \u2026 in England in 1799 \u2026 drew the 12 men \u2026 in 1921 \u2026 these 122,000 cases \u2026 under 13702 \u2026 600-somewhat cases \u2026 page 19 \u2026 purely equitable0 \u2026 Title 16-1501 in Eighteen Sixty Four \u2026 in England in Seventeen Ninety Nine \u2026 drew the Twelve men \u2026 in Nineteen Twenty One \u2026 these Hundred Twenty Two Thousand cases \u2026 under Thirteen Seven Oh Two \u2026 Six Hundred-somewhat cases \u2026 page Nineteen \u2026 purely equitable \u2026 Title Fifteen -- Sixteen Fifteen Oh One <p>(Transcript typo \u201cequitable0\u201d \u2192 \u201cequitable\u201d. Code \u201c16-1501\u201d \u2192 \u201cFifteen -- Sixteen Fifteen Oh One\u201d.)</p> <p>10) Already done in a previous round.</p>"},{"location":"asr_normalization_findings/#611-rule-status-verifications-and-exceptions-summary","title":"6.11 Rule status, verifications, and exceptions (summary)","text":"<p>Up-to-date status of all rules, verification counts, and situations where multiple solutions or context-dependent handling apply. Edited by Cursor.</p> <p>Fully verified rules (\u22652 instances)</p> Rule Instances Notes Case/docket ID 4 Term + number chunk (e.g. twenty one eleven sixty four). v. / vs. 4 Expansion to \u201cversus\u201d in \u201cX versus Y\u201d phrasing. Title (Mr. / Ms.) 2 Mr. \u2192 Mister. Years (19xx/20xx) 2 Spoken as two numbers (e.g. nineteen thirty five). Historical year (1xxx) 2 Same pattern (e.g. twelve fifteen, seventeen ninety one). Age / small number 2 e.g. ninety four, Twelve men. Currency 2 Symbol + number \u2192 \u201c\u2026 thousand dollars\u201d etc. Section number (legal) 2 Digit-style with \u201coh\u201d for zero (e.g. Eight Oh Two). Acronyms (BIA, USC, SEC, etc.) 2+ Letter-by-letter (Bee I Ay, Ess Ee Cee). \u201cNo.\u201d (negation) 2 Do not expand to \u201cnumber\u201d. \u201cNo.\u201d (number/citation) 2 Expand to \u201cnumber\u201d when followed by citation. Unspoken section headers 2 Strip \u201cORAL ARGUMENT OF \u2026\u201d etc. Vote tally (9-0, 7-2) 2 nine to zero, seven to two (Round 6). Roman numeral (VII, IV) 2 Seventh Amendment, ordinal; but see exceptions below. Percentage (50%) 2 fifty percent; also \u201c70 percent\u201d \u2192 Seventy percent (Round 6). Decade (1980s) 2 nineteen eighties / Nineteen Sixties (Round 6). Ordinal (word) 2 Fifth, Eighth, Seventh (Round 6). Statute citation 2 21 U.S.C. \u2192 twenty one U S C; Title/code numbers spoken (Round 6). <p>Exceptions and multiple solutions</p> <ul> <li>N-N / N\u2013M patterns: Same surface form can be:</li> <li>Vote tally (9-0, 7-2) \u2192 \u201cnine to zero\u201d, \u201cseven to two\u201d.</li> <li>Docket/ID (818-105-1-2) \u2192 \u201cEight Eighteen Dash One Oh Five Dash One Dash Two\u201d.</li> <li>Number range (6-8 employees) \u2192 \u201csix to eight\u201d.   Rule: Classify by context (sentence role, \u201cvote\u201d, \u201cdocket\u201d, \u201cemployees\u201d, etc.).</li> <li>\u201cv.\u201d in text: Two pronunciations:</li> <li>\u201cX versus Y\u201d (e.g. Capital Traction versus Hof): \u201cversus\u201d already in transcript; no change.</li> <li>\u201cX v. Y\u201d (case name): v. \u2192 \u201cVee\u201d (Parsons v. Bedford \u2192 Parsons Vee Bedford, Ross v. Bernhard, Whitehead v. Shattuck, Dairy Queen v. Wood). So \u201cv.\u201d in case citations is pronounced \u201cVee\u201d, not \u201cversus\u201d.</li> <li>Roman numeral vs acronym: Same letter(s) can be:</li> <li>Roman (Seventh Amendment) \u2192 \u201cSeventh\u201d.</li> <li>Acronym (N.O.V.) \u2192 \u201cEn Oh Vee\u201d; V-chip \u2192 \u201cVee chip\u201d. Rule: Context (Amendment vs motion name; \u201cchip\u201d vs numeral).</li> <li>Percent: With symbol (50%) or with word \u201cpercent\u201d (70 percent) \u2192 both spoken as number + \u201cpercent\u201d (Fifty percent, Seventy percent).</li> <li>Document/page numbers: Page 7 \u2192 page Seven; pages 613 and 614 \u2192 Six Thirteen and Fourteen; SEC docket 818-105-1-2 \u2192 digit/dash style (document ID, not vote).</li> <li>Code/section with dash: \u201c16-1501\u201d heard as \u201cFifteen -- Sixteen Fifteen Oh One\u201d (possible \u201cTitle 16\u201d + \u201c1501\u201d); \u201c13702\u201d \u2192 \u201cThirteen Seven Oh Two\u201d. Inconsistent hyphen handling; treat as statute/code and use digit-style.</li> <li>Transcript typos: e.g. \u201cequitable0\u201d \u2192 normalize to \u201cequitable\u201d when generating pronunciation.</li> <li>Quote marks: Unicode \u201c\u2026\u201d in transcript may correspond to \u201cand I quote \u2026 Close the quote\u201d in audio; optional normalization for ASR.</li> </ul> <p>Awareness-only (report, not yet rules)</p> <p>Non-ASCII, mixed-case, long all-caps, symbols, brackets, leading decimals (\u00a75.3). Prioritization: leading decimals and bracket non-speech strip (Round 7); then structural brackets and editorial <code>[= X]</code>.</p>"},{"location":"asr_normalization_plan/","title":"ASR Normalization Plan","text":"<p>Generated by Cursor \u2013 February 2026</p> <p>This document defines normalization rules, precedence, and overall flow for converting transcript text into forms that match spoken pronunciation (for ASR training or alignment). Where a rule is ambiguous, the normalizer outputs all options (e.g. <code>\"Vee\" | \"Versus\"</code>); a separate downstream step chooses the option that best matches ASR output.</p> <p>Interruption handling is also specified: utterances broken by a short interjection from another speaker are merged into a single utterance.</p> <p>Reference: asr_normalization_findings.md for verification and exceptions.</p>"},{"location":"asr_normalization_plan/#1-overall-flow","title":"1. Overall flow","text":"<p>Normalization is applied in phases in order. Later phases assume earlier ones have run (e.g. unspoken headers stripped before token-level rules).</p> Phase Name Purpose 1 Structural cleanup Strip unspoken headers; merge interruptions. 2 Context classification Classify ambiguous spans (N-N, \"v.\", Roman vs acronym). 3 Token-level rules Apply substitutions and expansions per rule. 4 (Optional) Downstream Choose among multi-option outputs using ASR hypothesis. <p>Input: Transcript (e.g. JSON with <code>turns</code>, each turn: <code>speaker_id</code>, <code>speaker_name</code>, <code>text</code>).</p> <p>Output: Normalized text per turn (or merged turn). For ambiguous rules, output may be a set of variants or a marked string (e.g. delimiter between options) so the downstream script can pick one.</p>"},{"location":"asr_normalization_plan/#2-phase-1-structural-cleanup","title":"2. Phase 1: Structural cleanup","text":""},{"location":"asr_normalization_plan/#21-strip-unspoken-section-headers","title":"2.1 Strip unspoken section headers","text":"<ul> <li>Detect: Substrings that are structural labels, not spoken:</li> <li><code>ORAL ARGUMENT OF \u2026</code>, <code>REBUTTAL OF \u2026</code>, <code>RESUMED ORAL ARGUMENT OF \u2026</code></li> <li>All-caps lines at turn start that match a known header pattern.</li> <li>Action: Remove these spans from the turn text (replace with empty or   trim). Do not normalize their content.</li> <li>Precedence: Apply first so alignment is not distorted by non-speech.</li> </ul>"},{"location":"asr_normalization_plan/#22-interruption-merge","title":"2.2 Interruption merge","text":"<ul> <li>Pattern: A sequence of three turns (A, B, C) where:</li> <li>A: Utterance ends with <code>--</code> (dash-dash, or em/en dash).</li> <li>B: Utterance by a different speaker, and short (e.g. word count     \u2264 N, or character count \u2264 M; configurable, e.g. N=15, M=80).</li> <li>C: Utterance by the same speaker as A, and starts with <code>--</code>.</li> <li>Action: Merge A and C into a single utterance (same speaker), excluding   B. Join A and C by:</li> <li>Removing the trailing <code>--</code> from A and the leading <code>--</code> from C, and</li> <li>Concatenating with a single space (or no space if C originally had none).</li> <li>Output: Replace the three turns with two turns: the merged turn (A\u2032 + C\u2032)   and no turn for B (B is dropped from the normalized transcript). Optionally   retain B elsewhere (e.g. metadata) for analysis.</li> <li>Precedence: Apply after stripping unspoken headers, before token-level   rules, so that the merged text is then normalized by Phase 3.</li> <li>Edge cases: If multiple consecutive interruptions match (e.g. A--, B1,   C--, B2, D--), apply greedily or iteratively: merge (A,C) first, then   consider (merged, D) with B2 as the short middle utterance.</li> </ul>"},{"location":"asr_normalization_plan/#3-phase-2-context-classification","title":"3. Phase 2: Context classification","text":"<p>These classifications are used in Phase 3 to decide which rule (or multi-option output) applies. No text change in this phase; only tags or context flags.</p> Span / token Classify as Used by <code>N-N</code> or <code>N\u2013M</code> (digits, dash) Vote tally (e.g. 9-0, 7-2) if context suggests vote (e.g. \u201cvote\u201d, \u201cheld\u201d, \u201cdecision\u201d). N-N rule \u2192 \"N to M\" for vote. Same Docket/ID if pattern like term-docket (e.g. 21-1164, 818-105-1-2) or \u201cdocket\u201d, \u201ccase\u201d, \u201cnumber\u201d. N-N rule \u2192 digit/dash spoken form. Same Number range if context suggests range (e.g. \u201cemployees\u201d, \u201cpages\u201d, \u201cbetween\u201d). N-N rule \u2192 \"N to M\". <code>v.</code> or <code>vs.</code> Case citation if between two capitalized names/abbrevs (e.g. Parsons v. Bedford). v. rule \u2192 \"Vee\". Same Versus (standalone) if transcript already has \u201cversus\u201d or \u201cv.\u201d in non-citation context. v. rule \u2192 \"Versus\". Roman-like letters (e.g. VII, IV, V-chip, N.O.V.) Roman numeral if Amendment/Circuit/Article (e.g. Seventh Amendment). Roman rule \u2192 ordinal/spelled. Same Acronym if motion name or product (e.g. N.O.V., V-chip). Acronym rule \u2192 letters (En Oh Vee, Vee chip). \u201cNo.\u201d Negation if next token is word (I, The, But, Thank, etc.). No. rule \u2192 leave \"No.\". Same Number/citation if next token is citation (e.g. 96-511, 89-1416). No. rule \u2192 \"number\". <p>When classification is uncertain, do not guess; pass the span to Phase 3 with all applicable options (see below).</p>"},{"location":"asr_normalization_plan/#4-phase-3-token-level-normalization-rules","title":"4. Phase 3: Token-level normalization rules","text":"<p>Rules are listed in precedence order within Phase 3. When a span matches more than one rule, the first matching rule wins unless the rule explicitly outputs multiple options.</p>"},{"location":"asr_normalization_plan/#41-rule-table-precedence-order","title":"4.1 Rule table (precedence order)","text":"# Rule Match Output (single) Output (ambiguous) 1 Unspoken header (handled in Phase 1) \u2014 \u2014 2 Case/docket ID Term-docket pattern (e.g. 21-1164, 13-1034). Term as word + second segment by digit group (e.g. \"twenty one eleven sixty four\"). \u2014 3 Vote tally N-N classified as vote (9-0, 7-2). \"nine to zero\", \"seven to two\". \u2014 4 Number range N-N classified as range (e.g. 6-8 employees). \"six to eight\". \u2014 5 Docket/ID (other) N-N or N-N-N-N classified as docket/ID. Digit/dash spoken (e.g. \"Eight Eighteen Dash One Oh Five Dash One Dash Two\"). \u2014 6 v. / vs. Token <code>v.</code> or <code>vs.</code> in case citation (X v. Y). \u2014 \"Vee\" | \"Versus\" 7 vs. (standalone) Token <code>vs.</code> or phrase \u201cversus\u201d already in text. Leave \"versus\". \u2014 8 Title Mr./Ms. <code>Mr.</code>, <code>Ms.</code>, <code>Mrs.</code>. Mr. \u2192 \"Mister\"; Ms. \u2192 \"Ms.\" or \"Miz\"; Mrs. \u2192 \"Missus\". Ms.: \"Ms.\" | \"Miz\" 9 Years 4-digit 19xx/20xx. Spoken year (e.g. \"nineteen thirty five\", \"twenty ten\"). \u2014 10 Historical year 4-digit 1xxx (e.g. 1215, 1791). Year-like (\"twelve fifteen\", \"seventeen ninety one\"). \u2014 11 Age / small number Small number in age-like context. Spoken number (e.g. \"ninety four\", \"twelve\"). \u2014 12 Currency <code>$</code> + number. Spoken number + \"dollars\" (e.g. \"forty thousand dollars\"). \u2014 13 Section number (legal) \"Section\" + digits, or standalone 3\u20134 digit in legal context. Digit-style, \"oh\" for zero (e.g. \"Section Eight Oh Two\"). \u2014 14 Statute citation \"N U.S.C.\", \"Title N\", code like 16-1501. \"twenty one U S C\", \"Title eighteen\"; code digit-style. \u2014 15 Acronyms (letter) Known acronym (BIA, USC, SEC, N.O.V., etc.). Letter-by-letter (e.g. \"Bee I Ay\", \"Ess Ee Cee\", \"En Oh Vee\"). \u2014 16 Acronym (word) Known word-pronunciation (e.g. WOS). \"Woes\". \u2014 17 Roman numeral VII, IV, etc. in Amendment/Circuit/Article context. Ordinal or spelled (\"Seventh\", \"fourth\"). \u2014 18 Roman vs acronym Same letters as Roman but context = motion/product (N.O.V., V-chip). \u2014 N.O.V.: \"En Oh Vee\"; V-chip: \"Vee chip\" (no extra option). 19 \u201cNo.\u201d (negation) \"No.\" next token word. Leave \"No.\". \u2014 20 \u201cNo.\u201d (number/citation) \"No.\" next token citation. \"number\" + rest (e.g. \"number ninety six five eleven\"). \u2014 21 Percentage <code>N%</code> or \"N percent\". Spoken number + \"percent\" (e.g. \"fifty percent\", \"Seventy percent\"). \u2014 22 Decade 19xxs, 20xxs. Spoken (e.g. \"nineteen eighties\", \"Nineteen Sixties\"). \u2014 23 Ordinal (word) Fifth, Seventh, Eighth, etc. Keep or lowercase (e.g. \"fifth\", \"Seventh\"). \u2014 24 Et al. \"et al.\". \u2014 \"et al.\" | \"and others\" 25 Quote marks / Unicode Curly quotes, em dash, ellipsis. Straight quote; dash \u2192 hyphen or \"to\"; ellipsis omit. Optional. 26 Leading decimal .N (not year). \"point\" + digits (e.g. \"point six six\"). \u2014 27 Non-speech brackets (Inaudible), [Laughter], [cough], etc. Strip. \u2014 28 Editorial [= X] [= Mr.], [= 1983]. Replace with normalized X, then strip brackets. \u2014"},{"location":"asr_normalization_plan/#42-multi-option-output-format","title":"4.2 Multi-option output format","text":"<p>When a rule outputs multiple options (e.g. v. \u2192 \"Vee\" | \"Versus\"), the normalizer should produce a representation that a downstream script can parse, for example:</p> <ul> <li>Delimiter: <code>\"Vee\" | \"Versus\"</code> (pipe-separated inside the string), or</li> <li>Structured: A list/set of variants per span, e.g. <code>[\"Vee\", \"Versus\"]</code>.</li> </ul> <p>The downstream step (separate script) compares each option to the ASR hypothesis (e.g. word error rate or alignment score) and selects the best match.</p>"},{"location":"asr_normalization_plan/#43-precedence-within-phase-3","title":"4.3 Precedence within Phase 3","text":"<ul> <li>Context-dependent rules (N-N, \"v.\", Roman vs acronym) use the   classification from Phase 2. If classification yields multiple possible   types, output all corresponding options (e.g. for \"v.\" output   \"Vee\" | \"Versus\").</li> <li>First match: For a given span, apply the first rule in the table that   matches. Exception: when the rule cell says \"Output (ambiguous)\", emit all   options and do not apply a later rule to the same span for that purpose.</li> <li>Order of application: Scan text (e.g. left-to-right or by token). For   each span, if it matches rule K, apply K; then advance past the span and   continue. Overlapping matches (e.g. \"21-1164\" as both case ID and number   range) are resolved by rule order: case/docket (2) before number range (4)   when pattern matches case ID.</li> </ul>"},{"location":"asr_normalization_plan/#5-interruption-handling-detail","title":"5. Interruption handling (detail)","text":""},{"location":"asr_normalization_plan/#51-definition","title":"5.1 Definition","text":"<ul> <li>Utterance A: Any turn whose <code>text</code> ends with <code>--</code> (two ASCII hyphens or   one em/en dash at end after optional whitespace).</li> <li>Short utterance B: A turn by a different speaker than A, with length   below a threshold (e.g. \u2264 15 words or \u2264 80 characters). Threshold is   configurable.</li> <li>Utterance C: A turn by the same speaker as A whose <code>text</code> starts   with <code>--</code> (after optional leading whitespace).</li> </ul>"},{"location":"asr_normalization_plan/#52-merge-algorithm","title":"5.2 Merge algorithm","text":"<ol> <li>Iterate over the list of turns in order.</li> <li>At each turn A (speaker S_A) that ends with <code>--</code>:</li> <li>Look at next turn B (speaker S_B \u2260 S_A). If B is missing or not short,      skip.</li> <li>Look at next turn C (speaker S_C). If S_C \u2260 S_A or C does not start with      <code>--</code>, skip.</li> <li>Merge: new text = <code>trim_end_dash(A.text) + \" \" + trim_start_dash(C.text)</code>.</li> <li>Replace A with merged turn (same speaker, new text, timestamps can be      A.start to C.end). Remove B and C from the list (or mark B as      \u201cinterruption\u201d, C merged into A).</li> <li>Advance so the next iteration does not use C again.</li> </ol>"},{"location":"asr_normalization_plan/#53-edge-cases","title":"5.3 Edge cases","text":"<ul> <li>Multiple dashes: Treat \u201c--\u201d as one interruption marker; allow optional   trailing/leading spaces.</li> <li>Same speaker B: If B is same speaker as A, do not treat as interruption   (no merge).</li> <li>Long B: If B exceeds the \u201cshort\u201d threshold, do not merge (A and C remain   separate).</li> </ul>"},{"location":"asr_normalization_plan/#6-summary","title":"6. Summary","text":"Phase What runs Output 1 Strip unspoken headers; merge interruptions (A--, B short, C--). Cleaned turns. 2 Classify N-N, v., Roman vs acronym, \u201cNo.\u201d context. Context tags. 3 Apply token-level rules in table order; emit multi-option where specified. Normalized text (or options). 4 (Separate script) Resolve options using ASR output. Final normalized form. <p>Reference: asr_normalization_findings.md for verified examples and exceptions (e.g. document IDs, code citations, typos).</p>"},{"location":"examples/","title":"Examples","text":"<pre><code>import oyez_sa_asr\n</code></pre>"},{"location":"huggingface-datasets-specs/","title":"HuggingFace Dataset Specifications","text":"<p>Edited by Claude</p> <p>Detailed specifications for each dataset tier.</p>"},{"location":"huggingface-datasets-specs/#dataset-1-oyez-sa-asr-raw","title":"Dataset 1: <code>oyez-sa-asr-raw</code>","text":"<p>Archive of original scraped files for reproducibility.</p> <pre><code>oyez-sa-asr-raw/\n\u251c\u2500\u2500 audio/{term}/{docket}/*.mp3, *.ogg\n\u251c\u2500\u2500 cases/{term}/{docket}.json\n\u251c\u2500\u2500 transcripts/{term}/{docket}.json\n\u2514\u2500\u2500 index/terms.json\n</code></pre> Aspect Detail Audio Original MP3 + OGG (both preserved) Metadata Raw JSON from Oyez API Size ~340 GB Updates Append-only (yearly)"},{"location":"huggingface-datasets-specs/#dataset-2-oyez-sa-asr-flex","title":"Dataset 2: <code>oyez-sa-asr-flex</code>","text":"<p>Processed FLAC recordings with parquet metadata references. CLI: <code>oyez dataset flex</code></p> <pre><code>oyez-sa-asr-flex/\n\u251c\u2500\u2500 audio/{term}/{docket}/\n\u2502   \u251c\u2500\u2500 {recording_id}.flac           # 24-bit FLAC\n\u2502   \u2514\u2500\u2500 {recording_id}.metadata.json  # Raw source + audio metadata\n\u2514\u2500\u2500 data/\n    \u251c\u2500\u2500 recordings.parquet         # Full recording metadata\n    \u2514\u2500\u2500 utterances.parquet         # Speaker turn refs (no audio)\n</code></pre> <p>Each processed FLAC has a corresponding metadata file (same stem, <code>.metadata.json</code>) that records the raw source and audio properties:</p> <ul> <li><code>source_path</code> \u2013 Path to the original cached file (MP3/OGG) used to   produce the FLAC.</li> <li><code>source_format</code> \u2013 <code>\"mp3\"</code> or <code>\"ogg\"</code>.</li> <li><code>source_era</code> \u2013 Era tag for format selection.</li> <li><code>duration</code>, <code>sample_rate</code>, <code>channels</code> \u2013 From the decoded audio.</li> <li><code>is_anomaly</code> (optional) \u2013 Set when silence/noise anomalies are detected.</li> </ul>"},{"location":"huggingface-datasets-specs/#configs","title":"Configs","text":"Config Description Audio <code>recordings</code> Full oral arguments File refs <code>utterances</code> Speaker turns Sliced on load"},{"location":"huggingface-datasets-specs/#utterances-schema","title":"Utterances Schema","text":"Column Type Description term string Court term docket string Docket number transcript_type string argument/opinion start_sec float Start timestamp end_sec float End timestamp text string Transcript speaker_name string Speaker name speaker_id int Speaker ID"},{"location":"huggingface-datasets-specs/#dataset-3-oyez-sa-asr-simple","title":"Dataset 3: <code>oyez-sa-asr-simple</code>","text":"<p>Embedded audio for zero-friction streaming access. CLI: <code>oyez dataset simple</code></p> <pre><code>oyez-sa-asr-simple/\n\u251c\u2500\u2500 oyez_sa_asr.py              # HuggingFace loading script\n\u251c\u2500\u2500 README.md                   # Dataset card\n\u251c\u2500\u2500 lt1m/data/utterances/       # &lt; 1 minute utterances\n\u251c\u2500\u2500 lt5m/data/utterances/       # 1-5 minute utterances\n\u2514\u2500\u2500 lt30m/data/utterances/      # 5-30 minute utterances\n</code></pre>"},{"location":"huggingface-datasets-specs/#usage","title":"Usage","text":"<pre><code>from datasets import load_dataset\n\n# Standard HuggingFace pattern\nds = load_dataset(\"path/to/datasets/simple\", split=\"lt1m\")\nsample = ds[0]\nprint(sample[\"audio\"][\"array\"])  # Decoded numpy array\nprint(sample[\"sentence\"])        # Transcription\n</code></pre>"},{"location":"huggingface-datasets-specs/#utterances-schema-huggingface-aligned","title":"Utterances Schema (HuggingFace-aligned)","text":"Column Type Description id string Unique utterance ID audio Audio Embedded FLAC bytes (auto-decoded) sentence string Transcript speaker string Speaker name duration float Duration in seconds term string Court term docket string Docket number start_sec float Start timestamp end_sec float End timestamp"},{"location":"huggingface-datasets-specs/#why-larger-2-flac","title":"Why Larger (~2\u00d7 FLAC)","text":"<ul> <li>Arrow row metadata per utterance</li> <li>Column value duplication</li> <li>Less efficient chunking than standalone FLAC</li> <li>Parquet index structures</li> </ul>"},{"location":"huggingface-datasets-specs/#flac-seekability","title":"FLAC Seekability","text":"<p>FLAC supports efficient seeking via SEEKTABLE:</p> <ul> <li>On-the-fly segment extraction</li> <li>HTTP Range requests for cloud storage</li> <li>Memory-efficient processing</li> </ul>"},{"location":"huggingface-datasets-versioning/","title":"HuggingFace Dataset Versioning","text":"<p>Edited by Claude</p> <p>Versioning strategy and annual release workflow.</p>"},{"location":"huggingface-datasets-versioning/#version-naming","title":"Version Naming","text":"<pre><code>v{year}.{patch}\n\nv2024.0  - Initial release with 2024 term\nv2024.1  - Bug fix (transcript corrections)\nv2025.0  - Add 2025 term\n</code></pre>"},{"location":"huggingface-datasets-versioning/#data-structure","title":"Data Structure","text":"<p>Sharded by term for incremental updates:</p> <pre><code>data/utterances/\n\u251c\u2500\u2500 1955.parquet\n\u251c\u2500\u2500 1956.parquet\n\u251c\u2500\u2500 ...\n\u2514\u2500\u2500 2024.parquet    # Added in v2024.0\n</code></pre>"},{"location":"huggingface-datasets-versioning/#loading-versions","title":"Loading Versions","text":"<pre><code># Latest\nds = load_dataset(\"org/oyez-sa-asr-flex\")\n\n# Pinned version\nds = load_dataset(\"org/oyez-sa-asr-flex\", revision=\"v2023.0\")\n\n# Specific terms\nds = load_dataset(\"org/oyez-sa-asr-flex\", \"utterances\",\n                  data_files=\"data/utterances/202*.parquet\")\n</code></pre>"},{"location":"huggingface-datasets-versioning/#term-configs","title":"Term Configs","text":"<pre><code>ds = load_dataset(\"org/oyez-sa-asr-flex\", \"all\")     # All terms\nds = load_dataset(\"org/oyez-sa-asr-flex\", \"modern\")  # 2000+\nds = load_dataset(\"org/oyez-sa-asr-flex\", \"recent\")  # Last 5 terms\nds = load_dataset(\"org/oyez-sa-asr-flex\", \"2024\")    # Single term\n</code></pre>"},{"location":"huggingface-datasets-versioning/#annual-release-workflow","title":"Annual Release Workflow","text":""},{"location":"huggingface-datasets-versioning/#timeline","title":"Timeline","text":"Month Activity October Term's oral arguments complete November Scrape and process December QA and release"},{"location":"huggingface-datasets-versioning/#release-commands","title":"Release Commands","text":"<pre><code># 1. Scrape &amp; process new term\noyez scrape cases --term 2025\noyez scrape transcripts --term 2025\noyez scrape audio --term 2025\noyez process cases --term 2025\noyez process transcripts --term 2025\noyez process audio --term 2025\n\n# 2. Create datasets\noyez dataset raw --term 2025\noyez dataset flex --term 2025\noyez dataset simple\n\n# 3. Publish to HuggingFace\noyez publish raw --repo-id org/oyez-sa-asr-raw\noyez publish flex --repo-id org/oyez-sa-asr-flex\noyez publish simple --repo-id org/oyez-sa-asr-simple\n</code></pre>"},{"location":"huggingface-datasets-versioning/#changelog-template","title":"CHANGELOG Template","text":"<pre><code>## [v2025.0] - 2025-12-01\n\n### Added\n\n- 2025 term: 72 arguments, 4,320 utterances\n\n### Stats\n\n- Recordings: 5,100 (+72)\n- Utterances: 510,000 (+4,320)\n- Storage: raw 345GB, flex 1.1TB, simple 2.2TB\n</code></pre>"},{"location":"huggingface-datasets/","title":"HuggingFace Dataset Architecture","text":"<p>Edited by Claude</p> <p>Three-tier dataset architecture for Oyez Supreme Court oral arguments.</p>"},{"location":"huggingface-datasets/#datasets-overview","title":"Datasets Overview","text":"Dataset CLI Command Purpose Size <code>oyez-sa-asr-raw</code> <code>oyez dataset raw</code> Archive of original MP3/OGG/JSON ~340 GB <code>oyez-sa-asr-flex</code> <code>oyez dataset flex</code> Processed FLAC + parquet refs ~1.1 TB <code>oyez-sa-asr-simple</code> <code>oyez dataset simple</code> Embedded audio for streaming ~2.2 TB <p>See detailed specifications in:</p> <ul> <li>Dataset Specifications</li> <li>Versioning &amp; Releases</li> </ul>"},{"location":"huggingface-datasets/#quick-start","title":"Quick Start","text":"<pre><code># Create datasets\noyez dataset raw --term 2024      # Package raw files\noyez dataset flex --term 2024     # Create FLAC + parquets\noyez dataset simple               # Embed audio (uses flex)\n\n# Publish to HuggingFace\noyez publish raw --repo-id org/oyez-sa-asr-raw\noyez publish flex --repo-id org/oyez-sa-asr-flex\noyez publish simple --repo-id org/oyez-sa-asr-simple\n</code></pre> <pre><code>from datasets import load_dataset\n\n# Streaming - no local storage needed\nds = load_dataset(\"org/oyez-sa-asr-simple\", \"utterances\", streaming=True)\n\n# Full recordings with on-the-fly slicing\nds = load_dataset(\"org/oyez-sa-asr-flex\", \"recordings\")\n\n# Specific term\nds = load_dataset(\"org/oyez-sa-asr-flex\", \"2024\")\n\n# Pinned version\nds = load_dataset(\"org/oyez-sa-asr-flex\", revision=\"v2024.0\")\n</code></pre>"},{"location":"huggingface-datasets/#choosing-the-right-dataset","title":"Choosing the Right Dataset","text":"Use Case Dataset Config ASR training (quick start) <code>oyez-sa-asr-simple</code> <code>utterances</code> Custom preprocessing <code>oyez-sa-asr-flex</code> <code>utterances</code> Full recording transcription <code>oyez-sa-asr-flex</code> <code>recordings</code> Reproduce from scratch <code>oyez-sa-asr-raw</code> -"},{"location":"huggingface-datasets/#size-growth","title":"Size &amp; Growth","text":"Dataset Current Annual Growth <code>oyez-sa-asr-raw</code> ~340 GB +5-7 GB <code>oyez-sa-asr-flex</code> ~1.1 TB +15-20 GB <code>oyez-sa-asr-simple</code> ~2.2 TB +30-40 GB"},{"location":"oyez_api_overview/","title":"Oyez API Data Overview","text":"<p>Generated by Claude - January 2026</p> <p>Summary of Oyez API structure and case data. See also: Audio Formats</p>"},{"location":"oyez_api_overview/#overview","title":"Overview","text":"<ul> <li>Total Cases: 8,477</li> <li>Term Range: 1850-2025 (75 unique court terms)</li> <li>Total Audio Recordings: 12,087</li> </ul>"},{"location":"oyez_api_overview/#data-pipeline","title":"Data Pipeline","text":"<pre><code>scrape index  \u2192  .cache/index/  \u2192  process index  \u2192  cases_index.json\n                                                                    \u2193\nscrape cases     \u2190  reads case URLs  \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2193\n.cache/cases/api.oyez.org/raw/*.json  (8,477 case detail files)\n</code></pre>"},{"location":"oyez_api_overview/#case-data-structure","title":"Case Data Structure","text":"<p>Each case JSON contains the following top-level fields:</p> Field Description <code>ID</code> Unique case identifier <code>name</code> Case name (e.g., \"Roe v. Wade\") <code>href</code> API URL for the case <code>docket_number</code> Court docket number <code>term</code> Supreme Court term (year) <code>first_party</code> / <code>second_party</code> Party names <code>timeline</code> List of case events with dates <code>facts_of_the_case</code> Factual background (HTML) <code>question</code> Legal question presented <code>conclusion</code> Court's conclusion <code>advocates</code> List of attorneys who argued <code>oral_argument_audio</code> Audio recordings of arguments <code>opinion_announcement</code> Audio of opinion announcements <code>decisions</code> Voting records with justice votes <code>written_opinion</code> Links to written opinions <code>heard_by</code> / <code>decided_by</code> Court composition"},{"location":"oyez_api_overview/#audio-recording-types","title":"Audio Recording Types","text":""},{"location":"oyez_api_overview/#1-oral-argument-audio","title":"1. Oral Argument Audio","text":"<p>Recordings of attorneys and justices during oral arguments.</p> Metric Value Total recordings 8,570 Cases with audio 7,383 Cases with multiple arguments 1,026 Unavailable recordings 86"},{"location":"oyez_api_overview/#2-opinion-announcement-audio","title":"2. Opinion Announcement Audio","text":"<p>Recordings of justices reading opinions from the bench.</p> Metric Value Total recordings 3,517 Cases with audio 3,457"},{"location":"oyez_api_overview/#dissenting-and-concurring-opinions","title":"Dissenting and Concurring Opinions","text":"<p>Justices may read separate opinions from the bench, recorded as multiple parts of the opinion announcement.</p> <p>Example: Glossip v. Gross (2015) - 4 audio parts:</p> Part Speaker Role 1 Roberts Majority announcement 2 Sotomayor Dissent 3 Breyer Dissent 4 Scalia Concurrence <p>The <code>opinion_type</code> field in votes identifies authors: <code>majority</code>, <code>dissent</code>, <code>concurrence</code>, <code>special concurrence</code>, <code>plurality</code>, or <code>none</code>.</p>"},{"location":"oyez_api_overview/#metadata-fields","title":"Metadata Fields","text":""},{"location":"oyez_api_overview/#timeline-event-types","title":"Timeline Event Types","text":"Event Description Argued Oral argument date Decided Decision date Granted Certiorari granted Reargued Case reargued"},{"location":"oyez_api_overview/#decision-types","title":"Decision Types","text":"Type Description majority opinion Most common per curiam Unsigned opinion plurality opinion No majority equally divided 4-4 split"},{"location":"oyez_api_overview/#vote-types","title":"Vote Types","text":"Vote Count majority 61,845 minority 13,637 none 3,516"},{"location":"oyez_api_overview/#unavailable-audio","title":"Unavailable Audio","text":"<p>Some oral arguments are marked unavailable with <code>public_note</code>:</p> <ul> <li>\"The audio for this oral argument is missing\"</li> <li>\"This case was dismissed before oral arguments\"</li> <li>\"This case was settled before arguments\"</li> <li>\"This argument audio is not available due to its exclusion from the   National Archives\"</li> </ul>"},{"location":"oyez_api_overview/#additional-data-sources","title":"Additional Data Sources","text":""},{"location":"oyez_api_overview/#argument-20-argument2_url","title":"Argument 2.0 (argument2_url)","text":"<ul> <li>32 cases have links to <code>argument2.oyez.org</code></li> <li>This is a blog/analysis site, not additional audio</li> </ul>"},{"location":"oyez_audio_formats/","title":"Oyez Audio Formats &amp; URLs","text":"<p>Generated by Claude - January 2026</p> <p>Detailed audio file formats, transcript structure, and URL patterns. See also: API Overview</p>"},{"location":"oyez_audio_formats/#audio-file-formats","title":"Audio File Formats","text":"<p>Each recording is available in 3 formats:</p> Format MIME Type S3 Bucket MP3 <code>audio/mpeg</code> <code>oyez.case-media.mp3</code> OGG <code>audio/ogg</code> <code>oyez.case-media.ogg</code> HLS <code>application/x-mpegURL</code> <code>oyez.case-media.hls</code>"},{"location":"oyez_audio_formats/#audio-file-naming-conventions","title":"Audio File Naming Conventions","text":"<p>Audio files follow specific naming patterns in S3:</p>"},{"location":"oyez_audio_formats/#oral-arguments","title":"Oral Arguments","text":"<pre><code>{docket}_{date}{suffix}.delivery.mp3\nExample: 95-7452_19961104a.delivery.mp3\n</code></pre>"},{"location":"oyez_audio_formats/#opinion-announcements","title":"Opinion Announcements","text":"Suffix Type <code>-opinion</code> Main/majority opinion <code>-opinion-1</code>, <code>-opinion-2</code> Numbered parts <code>-opinion-dissent</code> Dissenting opinion <code>-opinion-concur</code> Concurring opinion"},{"location":"oyez_audio_formats/#accessing-separate-opinion-audio","title":"Accessing Separate Opinion Audio","text":"<p>Data path:</p> <pre><code>Case JSON \u2192 opinion_announcement[] \u2192 href \u2192 case_media API \u2192 media_file[]\n</code></pre> <p>Title patterns identify opinion types:</p> Pattern Example Standard <code>Opinion Announcement - June 30, 2023</code> Numbered <code>Opinion Announcement - June 29, 2015 (Part 1)</code> Dissent (new) <code>Dissenting Opinion - Sotomayor - June 30, 2023</code> Dissent (old) <code>Opinion Announcement - June 19, 2017 (Dissent by Breyer)</code> Concurrence <code>Concurring Opinion - Jackson - June 27, 2024</code> <p>Example: 303 Creative v. Elenis (21-476):</p> <pre><code>{\n  \"opinion_announcement\": [\n    {\n      \"title\": \"Opinion Announcement - June 30, 2023\",\n      \"href\": \"...opinion_announcement_audio/25574\"\n    },\n    {\n      \"title\": \"Dissenting Opinion - Sotomayor - June 30, 2023\",\n      \"href\": \"...opinion_announcement_audio/25583\"\n    }\n  ]\n}\n</code></pre> <p>Fetching the dissent href returns:</p> <pre><code>.../21-476_20230630-opinion-dissent.delivery.mp3\n</code></pre>"},{"location":"oyez_audio_formats/#transcript-structure","title":"Transcript Structure","text":"<p>The case_media response includes timestamped transcripts:</p> <pre><code>{\n  \"transcript\": {\n    \"title\": \"Case Name\",\n    \"duration\": 3248.262,\n    \"sections\": [\n      {\n        \"start\": 0,\n        \"stop\": 1692.036,\n        \"turns\": [\n          {\n            \"start\": 0,\n            \"stop\": 9.747,\n            \"speaker\": {\n              \"ID\": 15141,\n              \"name\": \"William H. Rehnquist\",\n              \"last_name\": \"Rehnquist\"\n            },\n            \"text_blocks\": [\n              {\n                \"start\": 0,\n                \"stop\": 8.658,\n                \"text\": \"The Court will hear argument now...\"\n              }\n            ]\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"oyez_audio_formats/#url-patterns","title":"URL Patterns","text":"Resource URL Pattern Case list <code>api.oyez.org/cases?page={n}&amp;per_page={n}</code> Case detail <code>api.oyez.org/cases/{term}/{docket}</code> Oral argument <code>api.oyez.org/case_media/oral_argument_audio/{id}</code> Opinion audio <code>api.oyez.org/case_media/opinion_announcement_audio/{id}</code>"},{"location":"oyez_audio_formats/#s3-audio-urls","title":"S3 Audio URLs","text":"<pre><code>s3.amazonaws.com/oyez.case-media.mp3/case_data/{term}/{docket}/...\ns3.amazonaws.com/oyez.case-media.ogg/case_data/{term}/{docket}/...\ns3.amazonaws.com/oyez.case-media.hls/case_data/{term}/{docket}/...\n</code></pre>"},{"location":"oyez_audio_formats/#written-opinion-types","title":"Written Opinion Types","text":"Type Count syllabus 7,948 case 6,627 majority 1,514 concurring 950 dissenting 948"},{"location":"oyez_audio_formats/#processed-flac-and-metadata","title":"Processed FLAC and metadata","text":"<p>When cached audio (MP3/OGG) is converted to FLAC (e.g. via <code>oyez process audio</code>), each output FLAC is written alongside a metadata file with the same base name and extension <code>.metadata.json</code>. That file records the raw source and audio metadata so every processed FLAC is traceable to its source:</p> <ul> <li><code>source_path</code> \u2013 Absolute or relative path to the raw cached file   (MP3 or OGG) that was converted to this FLAC.</li> <li><code>source_format</code> \u2013 <code>\"mp3\"</code> or <code>\"ogg\"</code>.</li> <li><code>duration</code>, <code>sample_rate</code>, <code>channels</code> \u2013 From the decoded   audio; <code>is_anomaly</code> when anomalies (e.g. silence) are detected.</li> </ul> <p>Layout: <code>{output_dir}/{term}/{docket}/{recording_id}.flac</code> and <code>{recording_id}.metadata.json</code> in the same directory.</p>"},{"location":"oyez_audio_formats/#next-steps-for-audio-asr","title":"Next Steps for Audio ASR","text":"<p>To build an ASR dataset from this data:</p> <ol> <li>Extract audio URLs from cached case data</li> <li>Fetch case_media endpoints to get actual MP3/OGG URLs</li> <li>Download audio files from S3 buckets</li> <li>Extract transcripts from case_media responses</li> <li>Align audio with text using timestamp data</li> </ol>"},{"location":"transcript_structure/","title":"Oyez Transcript Structure Analysis","text":"<p>Generated by Claude - January 2026</p> <p>Analysis of 11,993 scraped transcript files from the Oyez case_media API.</p>"},{"location":"transcript_structure/#overview-statistics","title":"Overview Statistics","text":"Metric Value Total files 11,993 With transcript data 11,778 (98.2%) Without transcript 215 (1.8%) Damaged 1 Total audio duration 7,705 hours Average duration 39 min 15 sec"},{"location":"transcript_structure/#content-types","title":"Content Types","text":"Type Count Oral Arguments 8,297 Opinion Announcements 3,502 Dissenting Opinions 12 Concurring Opinions 2 Other 180"},{"location":"transcript_structure/#json-structure","title":"JSON Structure","text":"<p>Each transcript response contains:</p> <pre><code>{\n  \"id\": 12345,\n  \"title\": \"Oral Argument - March 21, 2023\",\n  \"damaged\": false,\n  \"unavailable\": false,\n  \"public_note\": null,\n  \"display_title\": null,\n  \"media_file\": [...],\n  \"transcript\": {...}\n}\n</code></pre>"},{"location":"transcript_structure/#media-files","title":"Media Files","text":"<p>Each response includes audio in 3 formats:</p> Format MIME Type Availability MP3 <code>audio/mpeg</code> 99.9% OGG <code>audio/ogg</code> 95.3% HLS <code>application/x-mpegURL</code> 95.3% <p>S3 URL pattern:</p> <pre><code>https://s3.amazonaws.com/oyez.case-media.{format}/case_data/{term}/{docket}/{filename}\n</code></pre>"},{"location":"transcript_structure/#transcript-object","title":"Transcript Object","text":"<pre><code>{\n  \"transcript\": {\n    \"title\": \"Case Name\",\n    \"duration\": 3248.262,\n    \"sections\": [...]\n  }\n}\n</code></pre>"},{"location":"transcript_structure/#hierarchical-structure","title":"Hierarchical Structure","text":"<pre><code>transcript\n  \u2514\u2500\u2500 sections[] (1-291 per transcript)\n        \u251c\u2500\u2500 start, stop (timestamps)\n        \u251c\u2500\u2500 byte_start, byte_stop (audio file offsets)\n        \u2514\u2500\u2500 turns[] (1-647 per section)\n              \u251c\u2500\u2500 start, stop (timestamps)\n              \u251c\u2500\u2500 byte_start, byte_stop\n              \u251c\u2500\u2500 speaker {...}\n              \u2514\u2500\u2500 text_blocks[] (1-185 per turn)\n                    \u251c\u2500\u2500 start, stop (timestamps)\n                    \u251c\u2500\u2500 byte_start, byte_stop\n                    \u2514\u2500\u2500 text (actual transcript text)\n</code></pre>"},{"location":"transcript_structure/#section-distribution","title":"Section Distribution","text":"Sections Transcripts 1 4,012 (34%) 2 1,322 (11%) 3 3,957 (34%) 4 1,820 (15%) 5+ 667 (6%) <p>Most transcripts have 1-4 sections. One outlier has 291 sections.</p>"},{"location":"transcript_structure/#totals","title":"Totals","text":"Element Count Sections 31,449 Turns 1,843,327 Text Blocks 4,180,491"},{"location":"transcript_structure/#speaker-data","title":"Speaker Data","text":""},{"location":"transcript_structure/#speaker-object","title":"Speaker Object","text":"<pre><code>{\n  \"speaker\": {\n    \"ID\": 15086,\n    \"name\": \"John G. Roberts, Jr.\",\n    \"last_name\": \"Roberts\",\n    \"identifier\": \"john_g_roberts_jr\",\n    \"href\": \"https://api.oyez.org/people/john_g_roberts_jr\",\n    \"roles\": [...],\n    \"thumbnail\": {...}\n  }\n}\n</code></pre>"},{"location":"transcript_structure/#top-speakers-by-turns","title":"Top Speakers by Turns","text":"Justice Turns Byron R. White 81,702 Antonin Scalia 58,158 Felix Frankfurter 54,967 John Paul Stevens 51,463 William H. Rehnquist 51,412 Potter Stewart 50,640 Hugo L. Black 45,202 <p>Unique speakers: 9,274 (includes justices, attorneys, and others)</p>"},{"location":"transcript_structure/#data-quality-issues","title":"Data Quality Issues","text":""},{"location":"transcript_structure/#null-speakers","title":"Null Speakers","text":"<p>89,761 turns (4.9%) have <code>speaker: null</code>.</p> <p>These represent unattributed speech, typically:</p> <ul> <li>Crosstalk or overlapping speech</li> <li>Unclear attribution in older recordings</li> <li>Audience reactions (laughter, etc.)</li> </ul> <p>Example:</p> <pre><code>{\n  \"speaker\": null,\n  \"text_blocks\": [{\"text\": \"0 [Generallaughter.]\"}]\n}\n</code></pre>"},{"location":"transcript_structure/#timestamp-anomalies","title":"Timestamp Anomalies","text":"<p>Negative durations: Some text blocks have <code>stop &lt; start</code>:</p> <pre><code>Start: 2807.32s, Stop: 2781.44s (duration: -25.88s)\nStart: 4939.75s, Stop: 0.00s (duration: -4939.75s)\n</code></pre> <p>This occurs in at least some transcripts due to:</p> <ul> <li>Timestamp reset at section boundaries</li> <li>Data entry errors in older transcripts</li> </ul> <p>Zero duration: 6,191 text blocks (0.15%)</p>"},{"location":"transcript_structure/#emptymissing-data","title":"Empty/Missing Data","text":"<ul> <li>6 empty text blocks (text is empty or whitespace)</li> <li>215 transcripts have no transcript data (older recordings)</li> <li>1 damaged recording marked explicitly</li> </ul>"},{"location":"transcript_structure/#text-block-characteristics","title":"Text Block Characteristics","text":"Metric Value Min length 2 chars Max length 4,634 chars Average 107 chars Median 78 chars Average duration 6.5 seconds <p>Most text blocks are short utterances (&lt; 150 chars).</p>"},{"location":"transcript_structure/#recommendations-for-asr-processing","title":"Recommendations for ASR Processing","text":""},{"location":"transcript_structure/#data-filtering","title":"Data Filtering","text":"<ol> <li>Skip null transcripts (215 files)</li> <li>Skip damaged recordings</li> <li>Handle null speakers - decide whether to include or exclude</li> </ol>"},{"location":"transcript_structure/#timestamp-handling","title":"Timestamp Handling","text":"<ol> <li>Validate durations - filter blocks with <code>stop &lt;= start</code></li> <li>Use byte offsets as fallback (100% present)</li> <li>Section boundaries - timestamps may reset per section</li> </ol>"},{"location":"transcript_structure/#text-preprocessing","title":"Text Preprocessing","text":"<ol> <li>Remove annotations like <code>[Generallaughter.]</code></li> <li>Handle empty blocks (6 total)</li> <li>Consider splitting very long blocks (&gt;2000 chars)</li> </ol>"},{"location":"transcript_structure/#audio-text-alignment","title":"Audio-Text Alignment","text":"<p>The data provides multiple alignment options:</p> <ul> <li>Timestamps (<code>start</code>/<code>stop</code> in seconds)</li> <li>Byte offsets (<code>byte_start</code>/<code>byte_stop</code> for audio file)</li> </ul> <p>Byte offsets are more reliable for older recordings.</p>"},{"location":"transcript_structure/#file-reference","title":"File Reference","text":"<p>Analysis scripts: <code>scripts/analyze_transcripts.py</code></p>"},{"location":"user-guide/","title":"User Guide","text":""},{"location":"user-guide/#what-is-oyez_sa_asr","title":"\ud83c\udfaf What is oyez_sa_asr?","text":"<p>Oyez project scraper, for the SA-ASR task</p>"},{"location":"user-guide/#usage","title":"\ud83d\udcd6 Usage","text":"<p>TODO</p>"},{"location":"user-guide/#next-steps","title":"\ud83d\udd17 Next Steps","text":"<ul> <li>Check out Examples for more use cases</li> </ul> <p>Need help? Check our GitHub Issues.</p>"}]}