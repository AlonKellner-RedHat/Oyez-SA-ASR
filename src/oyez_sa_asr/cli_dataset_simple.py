# Generated by Claude
"""Simple dataset command with embedded audio."""

import json
from pathlib import Path
from typing import Annotated, Any

import typer
from rich.console import Console
from tqdm import tqdm

from .cli_dataset_helpers import require_pyarrow

console = Console(force_terminal=True)


def register_simple_command(app: typer.Typer) -> None:
    """Register the simple command on the given app."""
    app.command(name="simple")(dataset_simple)


def dataset_simple(
    flex_dir: Annotated[
        Path,
        typer.Option("--flex-dir", "-f", help="Flex dataset directory"),
    ] = Path("datasets/flex"),
    output_dir: Annotated[
        Path,
        typer.Option("--output-dir", "-o", help="Dataset output directory"),
    ] = Path("datasets/simple"),
    shard_size_mb: Annotated[
        int,
        typer.Option("--shard-size", "-s", help="Parquet shard size in MB"),
    ] = 500,
) -> None:
    """Create oyez-sa-asr-simple dataset with embedded audio."""
    pa, pq = require_pyarrow()

    console.print("[bold]Creating oyez-sa-asr-simple dataset[/bold]")
    console.print(f"  Flex dir: {flex_dir}")
    console.print(f"  Output dir: {output_dir}")
    console.print(f"  Shard size: {shard_size_mb} MB")
    console.print()

    # Validate flex dataset
    utterances_pq = flex_dir / "data" / "utterances.parquet"
    if not utterances_pq.exists():
        console.print(f"[red]Error:[/red] {utterances_pq} not found.")
        console.print("Run 'oyez dataset flex' first.")
        raise typer.Exit(1)

    audio_dir = flex_dir / "audio"
    if not audio_dir.exists():
        console.print(f"[red]Error:[/red] {audio_dir} not found.")
        raise typer.Exit(1)

    output_dir.mkdir(parents=True, exist_ok=True)

    # Read utterances (metadata only, small)
    console.print("Reading utterances...")
    utterances = pq.read_table(utterances_pq).to_pylist()
    console.print(f"  Found {len(utterances)} utterances")

    audio_paths = _build_audio_paths(flex_dir, pq, audio_dir)

    # Stream embeddings directly to shards (memory-efficient)
    console.print("Embedding audio and writing shards...")
    stats = _stream_to_shards(
        utterances, audio_paths, output_dir, shard_size_mb, pa, pq
    )
    console.print(
        f"  Embedded {stats['embedded']} utterances, skipped {stats['skipped']}"
    )
    if stats["errors"] > 0:
        console.print(f"  [yellow]Warning:[/yellow] {stats['errors']} read errors")
    if stats["shards"] > 0:
        console.print(f"  Wrote {stats['shards']} shard files")

    # Create index
    with (flex_dir / "index.json").open() as f:
        flex_index = json.load(f)

    index = {
        "terms": flex_index.get("terms", []),
        "utterances_embedded": stats["embedded"],
        "shards": stats["shards"],
        "created_by": "oyez dataset simple",
    }
    with (output_dir / "index.json").open("w") as f:
        json.dump(index, f, indent=2)

    console.print()
    console.print("[bold green]Done![/bold green]")
    console.print(f"Output: {output_dir}")


def _build_audio_paths(
    flex_dir: Path, pq: Any, audio_dir: Path
) -> dict[tuple[str, str], Path]:
    """Build audio path lookup from recordings."""
    audio_paths: dict[tuple[str, str], Path] = {}
    recordings_pq = flex_dir / "data" / "recordings.parquet"
    if not recordings_pq.exists():
        return audio_paths

    for rec in pq.read_table(recordings_pq).to_pylist():
        key = (rec["term"], rec["docket"])
        path = audio_dir / rec["audio_path"]
        if path.exists():
            audio_paths[key] = path
    return audio_paths


def _stream_to_shards(
    utterances: list[dict],
    audio_paths: dict[tuple[str, str], Path],
    output_dir: Path,
    shard_size_mb: int,
    pa: Any,
    pq: Any,
) -> dict[str, int]:
    """Stream utterances with embedded audio directly to parquet shards.

    This avoids loading all audio into memory at once by writing shards
    incrementally as we reach the target size.
    """
    data_dir = output_dir / "data" / "utterances"
    data_dir.mkdir(parents=True, exist_ok=True)
    target_bytes = shard_size_mb * 1024 * 1024

    current_shard: list[dict] = []
    current_size = 0
    shard_num = 0
    embedded_count = 0
    skipped_count = 0
    error_count = 0

    for utt in tqdm(utterances, desc="Embedding", unit="utt"):
        key = (utt["term"], utt["docket"])
        audio_path = audio_paths.get(key)

        if audio_path is None or not audio_path.exists():
            skipped_count += 1
            continue

        # Read audio with error handling
        try:
            audio_bytes = audio_path.read_bytes()
        except OSError as e:
            console.print(f"  [yellow]Warning:[/yellow] Cannot read {audio_path}: {e}")
            error_count += 1
            continue

        row = {
            "audio": {"bytes": audio_bytes, "path": audio_path.name},
            "text": utt.get("text", ""),
            "speaker_name": utt.get("speaker_name"),
            "term": utt["term"],
            "docket": utt["docket"],
            "start_sec": utt.get("start_sec"),
            "end_sec": utt.get("end_sec"),
        }
        current_shard.append(row)
        current_size += len(audio_bytes)
        embedded_count += 1

        # Write shard when target size reached (frees memory)
        if current_size >= target_bytes:
            pq.write_table(
                pa.Table.from_pylist(current_shard),
                data_dir / f"train-{shard_num:05d}.parquet",
            )
            shard_num += 1
            current_shard = []
            current_size = 0

    # Write final shard
    if current_shard:
        pq.write_table(
            pa.Table.from_pylist(current_shard),
            data_dir / f"train-{shard_num:05d}.parquet",
        )
        shard_num += 1

    return {
        "embedded": embedded_count,
        "skipped": skipped_count,
        "errors": error_count,
        "shards": shard_num,
    }
