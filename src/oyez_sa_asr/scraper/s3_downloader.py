# Generated by Claude
"""S3 downloader implementation using aiobotocore."""

import re
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Any

from aiobotocore.session import get_session
from botocore import UNSIGNED
from botocore.config import Config
from botocore.exceptions import ClientError

from .models import FetchResult, RequestMetadata


def parse_s3_url(url: str) -> tuple[str, str]:
    """Parse S3 URL to extract bucket and key.

    Supports:
    - https://s3.amazonaws.com/bucket/key
    - https://bucket.s3.amazonaws.com/key

    Args:
        url: The S3 URL to parse.

    Returns
    -------
        Tuple of (bucket, key).

    Raises
    ------
        ValueError: If URL format is not recognized.
    """
    # Pattern: https://s3.amazonaws.com/bucket/key
    match = re.match(r"https://s3\.amazonaws\.com/([^/]+)/(.+)", url)
    if match:
        return match.group(1), match.group(2)

    # Pattern: https://bucket.s3.amazonaws.com/key
    match = re.match(r"https://([^.]+)\.s3\.amazonaws\.com/(.+)", url)
    if match:
        return match.group(1), match.group(2)

    msg = f"Unrecognized S3 URL format: {url}"
    raise ValueError(msg)


class S3Downloader:
    """S3 download backend using aiobotocore with anonymous access."""

    def __init__(
        self,
        cache_dir: Path,
        *,
        max_retries: int = 3,
    ) -> None:
        """Initialize the S3 downloader.

        Args:
            cache_dir: Directory for caching downloaded files.
            max_retries: Maximum retry attempts for transient failures.
        """
        self.cache_dir = cache_dir
        self.max_retries = max_retries
        self._session = get_session()

    def _get_local_path(self, bucket: str, key: str) -> Path:
        """Get local cache path for an S3 object."""
        return self.cache_dir / bucket / key

    def check_cache(self, request: RequestMetadata) -> FetchResult | None:
        """Check if file already exists in cache."""
        try:
            bucket, key = parse_s3_url(request.url)
        except ValueError:
            return None

        local_path = self._get_local_path(bucket, key)
        if local_path.exists():
            return FetchResult(
                url=request.url,
                success=True,
                status_code=200,
                data=str(local_path),
                content_type="application/octet-stream",
                from_cache=True,
            )
        return None

    def is_transient_failure(self, result: FetchResult) -> bool:
        """Check if failure is transient and should be retried."""
        if result.success:
            return False
        # S3 transient errors: throttling, service errors
        transient_codes = {429, 500, 502, 503, 504}
        return result.status_code in transient_codes or result.status_code is None

    async def fetch(self, client: Any, request: RequestMetadata) -> FetchResult:
        """Download file from S3 to local cache."""
        try:
            bucket, key = parse_s3_url(request.url)
        except ValueError as e:
            return FetchResult(
                url=request.url,
                success=False,
                error=str(e),
            )

        local_path = self._get_local_path(bucket, key)

        try:
            # Get object from S3
            response = await client.get_object(Bucket=bucket, Key=key)

            # Read body and write to file
            async with response["Body"] as stream:
                body = await stream.read()

            # Ensure directory exists
            local_path.parent.mkdir(parents=True, exist_ok=True)

            # Write to file
            local_path.write_bytes(body)

            return FetchResult(
                url=request.url,
                success=True,
                status_code=200,
                data=str(local_path),
                content_type=response.get("ContentType", "application/octet-stream"),
                from_cache=False,
            )

        except ClientError as e:
            error_code = e.response.get("Error", {}).get("Code", "Unknown")
            status_code = e.response.get("ResponseMetadata", {}).get(
                "HTTPStatusCode", None
            )
            return FetchResult(
                url=request.url,
                success=False,
                status_code=status_code,
                error=f"S3 error {error_code}: {e}",
            )
        except Exception as e:
            return FetchResult(
                url=request.url,
                success=False,
                error=f"Download error: {e}",
            )

    @asynccontextmanager
    async def create_client(self) -> Any:
        """Create aiobotocore S3 client with anonymous access."""
        async with self._session.create_client(
            "s3",
            config=Config(signature_version=UNSIGNED),
        ) as client:
            yield client
