# Generated by Claude
"""Scrape audio subcommand for oyez_sa_asr CLI."""

import asyncio
from pathlib import Path
from typing import Annotated

import typer
from rich.console import Console
from tqdm import tqdm

from .scraper import AdaptiveFetcher, FetchResult, RequestMetadata
from .scraper.parser_transcripts import extract_audio_urls

console = Console(force_terminal=True)


def add_audio_command(app: typer.Typer) -> None:
    """Add the audio command to the scrape app."""

    @app.command(name="audio")
    def scrape_audio(
        transcripts_dir: Annotated[
            Path,
            typer.Option(
                "--transcripts-dir", "-t", help="Directory with processed transcripts"
            ),
        ] = Path("data/transcripts"),
        cache_dir: Annotated[
            Path,
            typer.Option("--cache-dir", "-c", help="Directory for caching audio files"),
        ] = Path(".cache/audio"),
        max_parallelism: Annotated[
            int,
            typer.Option("--max-parallelism", "-p", help="Maximum parallel downloads"),
        ] = 64,
        min_improvement: Annotated[
            float,
            typer.Option(
                "--min-improvement",
                "-m",
                help="Min rate improvement to scale (0.25=25%)",
            ),
        ] = 0.25,
    ) -> None:
        """Download audio files from S3 using adaptive parallelism.

        Extracts audio URLs from processed transcripts and downloads MP3, OGG,
        and HLS files to the cache directory.
        """
        console.print("[bold]Scraping audio files (adaptive S3 parallelism)[/bold]")
        console.print(f"  Transcripts dir: {transcripts_dir}")
        console.print(f"  Cache dir: {cache_dir}")
        console.print(f"  Max parallelism: {max_parallelism}")
        console.print(f"  Min improvement: {min_improvement:.0%}")
        console.print()

        # Extract audio URLs from processed transcripts
        audio_urls = extract_audio_urls(transcripts_dir)

        if not audio_urls:
            console.print(
                "[yellow]Warning:[/yellow] No audio URLs found in transcripts."
            )
            console.print(
                "Run 'process transcripts' first to generate transcript metadata."
            )
            return

        console.print(f"Found {len(audio_urls)} audio URLs to download")
        console.print()

        # Create requests from URLs
        requests = [RequestMetadata(url=url) for url in audio_urls]

        # Use S3 fetcher
        fetcher = AdaptiveFetcher.create_s3(
            cache_dir,
            max_parallelism=max_parallelism,
            min_improvement=min_improvement,
        )

        stats = {"new": 0, "failed": 0}
        pbar: tqdm[None] | None = None

        def on_progress(
            completed: int, total: int, result: FetchResult, parallelism: int
        ) -> None:
            nonlocal pbar
            if pbar is None:
                pbar = tqdm(
                    total=total, desc="Downloading", unit="file", dynamic_ncols=True
                )

            if result.success:
                stats["new"] += 1
            else:
                stats["failed"] += 1

            pbar.n = completed
            pbar.set_postfix(
                parallelism=parallelism, new=stats["new"], failed=stats["failed"]
            )
            pbar.refresh()

        async def run_fetch() -> list[FetchResult]:
            return await fetcher.fetch_batch_adaptive(requests, on_progress)

        all_results = asyncio.run(run_fetch())
        if pbar is not None:
            pbar.close()

        cached = sum(1 for r in all_results if r.from_cache)
        new_downloads = sum(1 for r in all_results if r.success and not r.from_cache)
        failures = sum(1 for r in all_results if not r.success)

        console.print()
        console.print("[bold green]Done![/bold green]")
        console.print(f"  Already cached: {cached}")
        console.print(f"  New downloads: {new_downloads}")
        console.print(f"  Failures: {failures}")
        console.print(f"  Cache: {cache_dir}")
