# Generated by Claude
"""HuggingFace loading script for oyez-raw dataset.

For datasets v3.x with trust_remote_code=True:
    from datasets import load_dataset
    ds = load_dataset("datasets/raw", trust_remote_code=True)

For datasets v4.x, use parquet auto-discovery instead.
"""

import json
from collections.abc import Iterator
from pathlib import Path
from typing import Any

import datasets

from ..audio_source import parse_transcript_type_from_recording_id

_DESCRIPTION = """\
Oyez Supreme Court Oral Arguments - Raw Dataset.
Original MP3/OGG audio files with JSON transcript and case metadata.
"""

_HOMEPAGE = "https://www.oyez.org/"
_LICENSE = "CC-BY-4.0"


class OyezRaw(datasets.GeneratorBasedBuilder):
    """Oyez raw dataset with original audio and JSON metadata."""

    VERSION = datasets.Version("1.0.0")

    def _info(self) -> datasets.DatasetInfo:
        """Define dataset schema."""
        return datasets.DatasetInfo(
            description=_DESCRIPTION,
            features=datasets.Features(
                {
                    "recording_id": datasets.Value("string"),
                    "audio": datasets.Audio(),
                    "term": datasets.Value("string"),
                    "docket": datasets.Value("string"),
                    "recording_type": datasets.Value("string"),
                    "title": datasets.Value("string"),
                    "transcript": datasets.Value("string"),
                    "case_name": datasets.Value("string"),
                }
            ),
            homepage=_HOMEPAGE,
            license=_LICENSE,
        )

    def _split_generators(
        self,
        dl_manager: datasets.DownloadManager  # noqa: ARG002
        | datasets.StreamingDownloadManager,
    ) -> list[datasets.SplitGenerator]:
        """Define single train split."""
        return [
            datasets.SplitGenerator(
                name="train",
                gen_kwargs={},
            )
        ]

    def _generate_examples(  # type: ignore[override]
        self,
        **kwargs: Any,  # noqa: ARG002
    ) -> Iterator[tuple[int, dict[str, Any]]]:
        """Yield examples from raw dataset files."""
        base = Path(self.config.data_dir) if self.config.data_dir else Path(".")
        audio_dir = base / "audio"

        # Build case index: (term, docket) -> case data
        case_index: dict[tuple[str, str], dict] = {}
        cases_dir = base / "cases"
        if cases_dir.exists():
            for case_path in cases_dir.glob("*.json"):
                try:
                    with case_path.open() as f:
                        case_data = json.load(f)
                    term = str(case_data.get("term", ""))
                    docket = case_data.get("docket_number", "")
                    if term and docket:
                        case_index[(term, docket)] = case_data
                except (json.JSONDecodeError, OSError):
                    pass

        # Build transcript index: recording_id -> transcript data
        transcript_index: dict[str, dict] = {}
        transcripts_dir = base / "transcripts"
        if transcripts_dir.exists():
            for t_path in transcripts_dir.glob("*.json"):
                try:
                    with t_path.open() as f:
                        t_data = json.load(f)
                    for mf in t_data.get("media_file") or []:
                        if not mf:
                            continue
                        href = mf.get("href", "")
                        filename = href.rsplit("/", 1)[-1]
                        rec_id = filename.split(".")[0]
                        if rec_id:
                            transcript_index[rec_id] = t_data
                except (json.JSONDecodeError, OSError):
                    pass

        # Find all audio files and yield examples
        if not audio_dir.exists():
            return

        mp3_files = {p.stem.split(".")[0]: p for p in audio_dir.rglob("*.mp3")}
        ogg_files = {p.stem.split(".")[0]: p for p in audio_dir.rglob("*.ogg")}
        all_rec_ids = set(mp3_files.keys()) | set(ogg_files.keys())

        for idx, rec_id in enumerate(sorted(all_rec_ids)):
            mp3_path = mp3_files.get(rec_id)
            ogg_path = ogg_files.get(rec_id)
            audio_path = mp3_path or ogg_path
            if audio_path is None:
                continue

            term = audio_path.parent.parent.name
            docket = audio_path.parent.name

            # Get transcript data
            t_data = transcript_index.get(rec_id, {})
            title = t_data.get("title", "")
            transcript_json = json.dumps(t_data.get("transcript", {}))

            # Get case data
            case_data = case_index.get((term, docket), {})
            case_name = case_data.get("name", "")

            # Parse recording type from recording_id
            # Edited by Claude: Add recording_type field
            recording_type = parse_transcript_type_from_recording_id(rec_id)

            yield (
                idx,
                {
                    "recording_id": rec_id,
                    "audio": str(audio_path),
                    "term": term,
                    "docket": docket,
                    "recording_type": recording_type,
                    "title": title,
                    "transcript": transcript_json,
                    "case_name": case_name,
                },
            )
