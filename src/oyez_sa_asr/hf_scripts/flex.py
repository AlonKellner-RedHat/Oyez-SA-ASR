# Generated by Claude
"""HuggingFace loading script for oyez-flex dataset.

For datasets v3.x with trust_remote_code=True:
    # Load full recordings
    ds = load_dataset("datasets/flex", "recordings", trust_remote_code=True)

    # Load utterances with on-the-fly segment extraction
    ds = load_dataset("datasets/flex", "utterances", trust_remote_code=True)

For datasets v4.x, use parquet auto-discovery instead (full files only).
"""

import io
from collections.abc import Iterator
from pathlib import Path
from typing import Any, ClassVar

import av
import numpy as np
import pyarrow.parquet as pq

import datasets

_DESCRIPTION = """\
Oyez Supreme Court Oral Arguments - Flex Dataset.
Processed FLAC audio with parquet metadata for flexible access.
"""

_HOMEPAGE = "https://www.oyez.org/"
_LICENSE = "CC-BY-4.0"


class OyezFlex(datasets.GeneratorBasedBuilder):
    """Oyez flex dataset with processed FLAC audio."""

    VERSION = datasets.Version("1.0.0")

    BUILDER_CONFIGS: ClassVar[list[datasets.BuilderConfig]] = [
        datasets.BuilderConfig(
            name="recordings",
            description="Full recordings with FLAC audio",
        ),
        datasets.BuilderConfig(
            name="utterances",
            description="Utterance-level segments with extracted audio",
        ),
        datasets.BuilderConfig(
            name="speakers",
            description="Speaker statistics and aggregated data",
        ),
    ]

    DEFAULT_CONFIG_NAME = "recordings"

    def _info(self) -> datasets.DatasetInfo:
        """Define dataset schema based on config."""
        if self.config.name == "speakers":
            # Edited by Claude: by_term as dict mapping term to stats
            # HuggingFace doesn't support nested dicts directly, so we use a list of dicts
            features = datasets.Features(
                {
                    "speaker_id": datasets.Value("int64"),
                    "name": datasets.Value("string"),
                    "role": datasets.Value("string"),
                    "total_recordings": datasets.Value("int64"),
                    "total_cases": datasets.Value("int64"),
                    "total_turns": datasets.Value("int64"),
                    "total_duration_sec": datasets.Value("float64"),
                    "total_word_count": datasets.Value("int64"),
                    "first_appearance": datasets.Value("string"),
                    "last_appearance": datasets.Value("string"),
                    "by_term": datasets.Sequence(
                        datasets.Features(
                            {
                                "term": datasets.Value("string"),
                                "recordings": datasets.Value("int64"),
                                "turns": datasets.Value("int64"),
                                "duration_seconds": datasets.Value("float64"),
                                "word_count": datasets.Value("int64"),
                            }
                        )
                    ),
                }
            )
        elif self.config.name == "recordings":
            features = datasets.Features(
                {
                    "recording_id": datasets.Value("string"),
                    "audio": datasets.Audio(sampling_rate=22050),
                    "term": datasets.Value("string"),
                    "docket": datasets.Value("string"),
                    "recording_type": datasets.Value("string"),
                    "duration_sec": datasets.Value("float64"),
                    "sample_rate": datasets.Value("int64"),
                    "channels": datasets.Value("int64"),
                    "source_format": datasets.Value("string"),
                    "source_era": datasets.Value("string"),
                    "justice_speakers": datasets.Sequence(datasets.Value("int64")),
                    "other_speakers": datasets.Sequence(datasets.Value("int64")),
                    "total_speakers": datasets.Value("int64"),
                }
            )
        else:  # utterances
            features = datasets.Features(
                {
                    "id": datasets.Value("string"),
                    "audio": datasets.Audio(sampling_rate=22050),
                    "text": datasets.Value("string"),
                    "speaker_name": datasets.Value("string"),
                    "speaker_id": datasets.Value("int64"),
                    "is_justice": datasets.Value("bool"),
                    "start_sec": datasets.Value("float64"),
                    "end_sec": datasets.Value("float64"),
                    "duration_sec": datasets.Value("float64"),
                    "term": datasets.Value("string"),
                    "docket": datasets.Value("string"),
                    "recording_type": datasets.Value("string"),
                }
            )

        return datasets.DatasetInfo(
            description=_DESCRIPTION,
            features=features,
            homepage=_HOMEPAGE,
            license=_LICENSE,
        )

    def _split_generators(
        self,
        dl_manager: datasets.DownloadManager  # noqa: ARG002
        | datasets.StreamingDownloadManager,
    ) -> list[datasets.SplitGenerator]:
        """Define single train split."""
        return [
            datasets.SplitGenerator(
                name="train",
                gen_kwargs={},
            )
        ]

    def _generate_examples(  # type: ignore[override]
        self,
        **kwargs: Any,  # noqa: ARG002
    ) -> Iterator[tuple[int, dict[str, Any]]]:
        """Yield examples based on config."""
        base = Path(self.config.data_dir) if self.config.data_dir else Path(".")
        audio_dir = base / "audio"
        data_dir = base / "data"

        if self.config.name == "recordings":
            yield from self._generate_recordings(data_dir, audio_dir)
        elif self.config.name == "utterances":
            yield from self._generate_utterances(data_dir, audio_dir)
        elif self.config.name == "speakers":
            yield from self._generate_speakers(data_dir)

    def _generate_recordings(
        self, data_dir: Path, audio_dir: Path
    ) -> Iterator[tuple[int, dict[str, Any]]]:
        """Yield full recording examples."""
        recordings_pq = data_dir / "recordings.parquet"
        if not recordings_pq.exists():
            return

        table = pq.read_table(recordings_pq)
        for idx, row in enumerate(table.to_pylist()):
            audio_path = audio_dir / row["audio_path"]
            if not audio_path.exists():
                continue

            yield (
                idx,
                {
                    "recording_id": row["recording_id"],
                    "audio": str(audio_path),
                    "term": row["term"],
                    "docket": row["docket"],
                    "recording_type": row.get(
                        "transcript_type", row.get("recording_type", "unknown")
                    ),
                    "duration_sec": row["duration_sec"],
                    "sample_rate": row["sample_rate"],
                    "channels": row["channels"],
                    "source_format": row["source_format"],
                    "source_era": row["source_era"],
                    "justice_speakers": row.get("justice_speakers", []),
                    "other_speakers": row.get("other_speakers", []),
                    "total_speakers": row.get("total_speakers", 0),
                },
            )

    def _generate_utterances(
        self, data_dir: Path, audio_dir: Path
    ) -> Iterator[tuple[int, dict[str, Any]]]:
        """Yield utterance examples with on-the-fly segment extraction."""
        recordings_pq = data_dir / "recordings.parquet"
        utterances_pq = data_dir / "utterances.parquet"

        if not recordings_pq.exists() or not utterances_pq.exists():
            return

        # Build recording lookup
        # Edited by Claude: Use (term, docket, transcript_type) as key
        rec_table = pq.read_table(recordings_pq)
        rec_lookup = {}
        for row in rec_table.to_pylist():
            transcript_type = row.get(
                "transcript_type", row.get("recording_type", "unknown")
            )
            key = (row["term"], row["docket"], transcript_type)
            if key not in rec_lookup:
                rec_lookup[key] = []
            rec_lookup[key].append(row)

        # Cache for loaded audio files
        audio_cache: dict[str, tuple[np.ndarray, int]] = {}

        utt_table = pq.read_table(utterances_pq)
        idx = 0

        for row in utt_table.to_pylist():
            if not row.get("valid", True):
                continue

            transcript_type = row.get("transcript_type", "unknown")
            key = (row["term"], row["docket"], transcript_type)
            recs = rec_lookup.get(key, [])
            if not recs:
                continue

            # Use first matching recording
            rec = recs[0]
            audio_path = audio_dir / rec["audio_path"]
            if not audio_path.exists():
                continue

            # Load audio if not cached
            cache_key = str(audio_path)
            if cache_key not in audio_cache:
                try:
                    container = av.open(str(audio_path))
                    stream = container.streams.audio[0]
                    sample_rate = stream.rate
                    frames = []
                    for frame in container.decode(audio=0):
                        frames.append(frame.to_ndarray())
                    container.close()
                    audio_data = np.concatenate(frames, axis=1).flatten()
                    audio_cache[cache_key] = (audio_data, sample_rate)
                except Exception:  # noqa: S112
                    continue

            audio_data, sample_rate = audio_cache[cache_key]

            # Extract segment
            start_sample = int(row["start_sec"] * sample_rate)
            end_sample = int(row["end_sec"] * sample_rate)
            end_sample = min(end_sample, len(audio_data))
            if start_sample >= end_sample:
                continue

            segment = audio_data[start_sample:end_sample]

            # Encode segment as WAV bytes for HF Audio feature
            output = io.BytesIO()
            out_container = av.open(output, mode="w", format="wav")
            out_stream: av.AudioStream = out_container.add_stream(  # type: ignore[assignment]
                "pcm_f32le", rate=sample_rate
            )
            out_stream.layout = "mono"
            frame = av.AudioFrame.from_ndarray(
                segment.reshape(1, -1).astype(np.float32), format="flt", layout="mono"
            )
            frame.rate = sample_rate
            for packet in out_stream.encode(frame):
                out_container.mux(packet)
            for packet in out_stream.encode():
                out_container.mux(packet)
            out_container.close()

            transcript_type = row.get("transcript_type", "unknown")
            utt_id = (
                f"{row['term']}_{row['docket']}_{transcript_type}_{row['turn_index']}"
            )

            yield (
                idx,
                {
                    "id": utt_id,
                    "audio": {"bytes": output.getvalue(), "path": f"{utt_id}.wav"},
                    "text": row.get("text", ""),
                    "speaker_name": row.get("speaker_name", ""),
                    "speaker_id": row.get("speaker_id") or 0,
                    "is_justice": row.get("is_justice", False),
                    "start_sec": row["start_sec"],
                    "end_sec": row["end_sec"],
                    "duration_sec": row["duration_sec"],
                    "term": row["term"],
                    "docket": row["docket"],
                    "recording_type": transcript_type,
                },
            )
            idx += 1

    def _generate_speakers(
        self, data_dir: Path
    ) -> Iterator[tuple[int, dict[str, Any]]]:
        """Yield speaker examples from parquet.

        Edited by Claude: Added speakers mode generation.
        """
        speakers_pq = data_dir / "speakers.parquet"
        if not speakers_pq.exists():
            return

        table = pq.read_table(speakers_pq)
        for idx, row in enumerate(table.to_pylist()):
            # Convert by_term dict to list of dicts for Sequence feature
            by_term_list = [
                {"term": term, **stats}
                for term, stats in row.get("by_term", {}).items()
            ]

            yield (
                idx,
                {
                    "speaker_id": row["speaker_id"],
                    "name": row["name"],
                    "role": row["role"],
                    "total_recordings": row["total_recordings"],
                    "total_cases": row["total_cases"],
                    "total_turns": row["total_turns"],
                    "total_duration_sec": row["total_duration_sec"],
                    "total_word_count": row["total_word_count"],
                    "first_appearance": row.get("first_appearance") or "",
                    "last_appearance": row.get("last_appearance") or "",
                    "by_term": by_term_list,
                },
            )

    def _generate_speakers(
        self, data_dir: Path
    ) -> Iterator[tuple[int, dict[str, Any]]]:
        """Yield speaker examples from parquet."""
        speakers_pq = data_dir / "speakers.parquet"
        if not speakers_pq.exists():
            return

        table = pq.read_table(speakers_pq)
        for idx, row in enumerate(table.to_pylist()):
            # Convert by_term dict to list of dicts for Sequence feature
            by_term_list = [
                {"term": term, **stats}
                for term, stats in row.get("by_term", {}).items()
            ]

            yield (
                idx,
                {
                    "speaker_id": row["speaker_id"],
                    "name": row["name"],
                    "role": row["role"],
                    "total_recordings": row["total_recordings"],
                    "total_cases": row["total_cases"],
                    "total_turns": row["total_turns"],
                    "total_duration_sec": row["total_duration_sec"],
                    "total_word_count": row["total_word_count"],
                    "first_appearance": row.get("first_appearance") or "",
                    "last_appearance": row.get("last_appearance") or "",
                    "by_term": by_term_list,
                },
            )
